{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FizzBuzz.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6N2C0ARJAbB5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Importing the dependencies\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9ahafuqAlFA",
        "colab_type": "text"
      },
      "source": [
        "#Software Logic v1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnY_WbYIAjfy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fizzbuzz_responder(n):\n",
        "  if n%3 == 0 and n%5 ==0:\n",
        "    return \"FizzBuzz\"\n",
        "  elif n%3 == 0:\n",
        "    return \"Fizz\"\n",
        "  elif n%5 == 0:\n",
        "    return \"Buzz\"\n",
        "  else:\n",
        "    return \"Other\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uyEaNS2A7Z-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_generator(start_pt, end_pt):\n",
        "  '''\n",
        "  Instructions: Enter the starting number and end number for the series for which you desires the FizzBuzz sequence\n",
        "  Output : Returns a corresponding list  \n",
        "  '''\n",
        "  \n",
        "  data = []\n",
        "  for i in range(start_pt, end_pt + 1):\n",
        "    data.append(fizzbuzz_responder(i))\n",
        "\n",
        "  return data"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CispHM3BraR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "04fc1142-0e63-4a8c-f3d4-f2299d48db37"
      },
      "source": [
        "#Software logic v1\n",
        "\n",
        "software_output = data_generator(1,100)  \n",
        "for i in range(len(software_output)):\n",
        "  print(i+1 , \"=\", software_output[i] )"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 = Other\n",
            "2 = Other\n",
            "3 = Fizz\n",
            "4 = Other\n",
            "5 = Buzz\n",
            "6 = Fizz\n",
            "7 = Other\n",
            "8 = Other\n",
            "9 = Fizz\n",
            "10 = Buzz\n",
            "11 = Other\n",
            "12 = Fizz\n",
            "13 = Other\n",
            "14 = Other\n",
            "15 = FizzBuzz\n",
            "16 = Other\n",
            "17 = Other\n",
            "18 = Fizz\n",
            "19 = Other\n",
            "20 = Buzz\n",
            "21 = Fizz\n",
            "22 = Other\n",
            "23 = Other\n",
            "24 = Fizz\n",
            "25 = Buzz\n",
            "26 = Other\n",
            "27 = Fizz\n",
            "28 = Other\n",
            "29 = Other\n",
            "30 = FizzBuzz\n",
            "31 = Other\n",
            "32 = Other\n",
            "33 = Fizz\n",
            "34 = Other\n",
            "35 = Buzz\n",
            "36 = Fizz\n",
            "37 = Other\n",
            "38 = Other\n",
            "39 = Fizz\n",
            "40 = Buzz\n",
            "41 = Other\n",
            "42 = Fizz\n",
            "43 = Other\n",
            "44 = Other\n",
            "45 = FizzBuzz\n",
            "46 = Other\n",
            "47 = Other\n",
            "48 = Fizz\n",
            "49 = Other\n",
            "50 = Buzz\n",
            "51 = Fizz\n",
            "52 = Other\n",
            "53 = Other\n",
            "54 = Fizz\n",
            "55 = Buzz\n",
            "56 = Other\n",
            "57 = Fizz\n",
            "58 = Other\n",
            "59 = Other\n",
            "60 = FizzBuzz\n",
            "61 = Other\n",
            "62 = Other\n",
            "63 = Fizz\n",
            "64 = Other\n",
            "65 = Buzz\n",
            "66 = Fizz\n",
            "67 = Other\n",
            "68 = Other\n",
            "69 = Fizz\n",
            "70 = Buzz\n",
            "71 = Other\n",
            "72 = Fizz\n",
            "73 = Other\n",
            "74 = Other\n",
            "75 = FizzBuzz\n",
            "76 = Other\n",
            "77 = Other\n",
            "78 = Fizz\n",
            "79 = Other\n",
            "80 = Buzz\n",
            "81 = Fizz\n",
            "82 = Other\n",
            "83 = Other\n",
            "84 = Fizz\n",
            "85 = Buzz\n",
            "86 = Other\n",
            "87 = Fizz\n",
            "88 = Other\n",
            "89 = Other\n",
            "90 = FizzBuzz\n",
            "91 = Other\n",
            "92 = Other\n",
            "93 = Fizz\n",
            "94 = Other\n",
            "95 = Buzz\n",
            "96 = Fizz\n",
            "97 = Other\n",
            "98 = Other\n",
            "99 = Fizz\n",
            "100 = Buzz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2TUSpHSCITk",
        "colab_type": "text"
      },
      "source": [
        "#Machine Learning Approach v2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_UeJatjCHej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train data 101,1000\n",
        "#test data 1,100"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjDEGmy5CSDK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#to encode Y we have used one-hot encoding\n",
        "#to encode X we have used binary encoding \n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "def machine_learning_datagenerator(start_pt,end_pt):\n",
        "  X_data = list(range(start_pt,end_pt+1))\n",
        "  y_label = data_generator(start_pt,end_pt)\n",
        "  \n",
        "  oh = OneHotEncoder()\n",
        "  y_label = oh.fit_transform(np.array(y_label).reshape((end_pt - start_pt + 1),1)).toarray()\n",
        "\n",
        "  processedData = []\n",
        "  for dataInstance in X_data:\n",
        "        \n",
        "    #range is 10 as model will have 10 input nodes and they should be capable of storing numerical values 1000 in binary form\n",
        "    processedData.append([dataInstance >> d & 1 for d in range(10)]) #right shift dataInstance by d bits and append to processedData\n",
        "    \n",
        "  X_data = np.array(processedData) #return processedData to function name-processData\n",
        "\n",
        "  return X_data, y_label"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uuOXsz0HLvO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "60ce5875-8969-418f-ce2b-6b5f5078ee0d"
      },
      "source": [
        "#Neural Network Model\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.callbacks import EarlyStopping, TensorBoard\n",
        "\n",
        "input_size = 10                     #initializing number of nodes to be used in input layer\n",
        "drop_out = 0.2\n",
        "first_dense_layer_nodes  = 1000     #total number of nodes in hidden layer \n",
        "second_dense_layer_nodes = 4        #total number of nodes in output layer\n",
        "\n",
        "\n",
        "def neural_network():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(first_dense_layer_nodes, activation = \"relu\", input_dim = input_size))\n",
        "  model.add(Dropout(drop_out))\n",
        "  model.add(Dense(second_dense_layer_nodes, activation = \"softmax\"))\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  model.compile(optimizer = \"rmsprop\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
        "\n",
        "  return model\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhNCgPC7Jwyj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "fd71bfae-3ad0-4c31-a0e8-79cdbac57d07"
      },
      "source": [
        "model = neural_network()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 1000)              11000     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 4)                 4004      \n",
            "=================================================================\n",
            "Total params: 15,004\n",
            "Trainable params: 15,004\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciXKm34mJ8f6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creating data\n",
        "X_train, y_train = machine_learning_datagenerator(101,1000)\n",
        "X_test, y_test = machine_learning_datagenerator(1,100)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAObobDxKOje",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a53fb183-f77e-4603-b10f-eafc8c04c610"
      },
      "source": [
        "num_epochs = 10000          #maximum number of epochs\n",
        "model_batch_size = 128      #size of a single batch \n",
        "tb_batch_size = 32\n",
        "early_patience = 100        #initializing value of 'patience' parameter\n",
        "\n",
        "tensorboard_cb   = TensorBoard(log_dir='logs', batch_size= tb_batch_size, write_graph= True)\n",
        "earlystopping_cb = EarlyStopping(monitor='val_loss', verbose=1, patience=early_patience, mode='min')\n",
        "\n",
        "model.fit(X_train,y_train, batch_size = model_batch_size, epochs = num_epochs, verbose= 1, callbacks  = [tensorboard_cb,earlystopping_cb], validation_data=(X_test, y_test))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v2.py:92: UserWarning: The TensorBoard callback `batch_size` argument (for histogram computation) is deprecated with TensorFlow 2.0. It will be ignored.\n",
            "  warnings.warn('The TensorBoard callback `batch_size` argument '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 900 samples, validate on 100 samples\n",
            "Epoch 1/10000\n",
            "900/900 [==============================] - 0s 183us/step - loss: 1.2140 - accuracy: 0.4822 - val_loss: 1.2400 - val_accuracy: 0.3900\n",
            "Epoch 2/10000\n",
            "900/900 [==============================] - 0s 45us/step - loss: 1.1621 - accuracy: 0.5211 - val_loss: 1.1936 - val_accuracy: 0.5300\n",
            "Epoch 3/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 1.1498 - accuracy: 0.5333 - val_loss: 1.1785 - val_accuracy: 0.5300\n",
            "Epoch 4/10000\n",
            "900/900 [==============================] - 0s 48us/step - loss: 1.1490 - accuracy: 0.5333 - val_loss: 1.1696 - val_accuracy: 0.5300\n",
            "Epoch 5/10000\n",
            "900/900 [==============================] - 0s 48us/step - loss: 1.1485 - accuracy: 0.5333 - val_loss: 1.1841 - val_accuracy: 0.5300\n",
            "Epoch 6/10000\n",
            "900/900 [==============================] - 0s 59us/step - loss: 1.1498 - accuracy: 0.5344 - val_loss: 1.1652 - val_accuracy: 0.5300\n",
            "Epoch 7/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 1.1370 - accuracy: 0.5333 - val_loss: 1.1796 - val_accuracy: 0.5300\n",
            "Epoch 8/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 1.1416 - accuracy: 0.5333 - val_loss: 1.1744 - val_accuracy: 0.5300\n",
            "Epoch 9/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 1.1400 - accuracy: 0.5333 - val_loss: 1.1833 - val_accuracy: 0.5300\n",
            "Epoch 10/10000\n",
            "900/900 [==============================] - 0s 65us/step - loss: 1.1357 - accuracy: 0.5333 - val_loss: 1.1748 - val_accuracy: 0.5300\n",
            "Epoch 11/10000\n",
            "900/900 [==============================] - 0s 61us/step - loss: 1.1335 - accuracy: 0.5333 - val_loss: 1.1641 - val_accuracy: 0.5300\n",
            "Epoch 12/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 1.1368 - accuracy: 0.5333 - val_loss: 1.1792 - val_accuracy: 0.5300\n",
            "Epoch 13/10000\n",
            "900/900 [==============================] - 0s 48us/step - loss: 1.1395 - accuracy: 0.5311 - val_loss: 1.1546 - val_accuracy: 0.5300\n",
            "Epoch 14/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 1.1291 - accuracy: 0.5333 - val_loss: 1.1630 - val_accuracy: 0.5300\n",
            "Epoch 15/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 1.1283 - accuracy: 0.5333 - val_loss: 1.1590 - val_accuracy: 0.5300\n",
            "Epoch 16/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 1.1274 - accuracy: 0.5333 - val_loss: 1.1554 - val_accuracy: 0.5300\n",
            "Epoch 17/10000\n",
            "900/900 [==============================] - 0s 58us/step - loss: 1.1256 - accuracy: 0.5333 - val_loss: 1.1519 - val_accuracy: 0.5300\n",
            "Epoch 18/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 1.1274 - accuracy: 0.5333 - val_loss: 1.1467 - val_accuracy: 0.5300\n",
            "Epoch 19/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 1.1189 - accuracy: 0.5333 - val_loss: 1.1486 - val_accuracy: 0.5300\n",
            "Epoch 20/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 1.1193 - accuracy: 0.5333 - val_loss: 1.1571 - val_accuracy: 0.5300\n",
            "Epoch 21/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 1.1145 - accuracy: 0.5333 - val_loss: 1.1450 - val_accuracy: 0.5300\n",
            "Epoch 22/10000\n",
            "900/900 [==============================] - 0s 54us/step - loss: 1.1163 - accuracy: 0.5333 - val_loss: 1.1395 - val_accuracy: 0.5300\n",
            "Epoch 23/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 1.1150 - accuracy: 0.5333 - val_loss: 1.1352 - val_accuracy: 0.5300\n",
            "Epoch 24/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 1.1094 - accuracy: 0.5333 - val_loss: 1.1330 - val_accuracy: 0.5300\n",
            "Epoch 25/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 1.1017 - accuracy: 0.5333 - val_loss: 1.1345 - val_accuracy: 0.5300\n",
            "Epoch 26/10000\n",
            "900/900 [==============================] - 0s 55us/step - loss: 1.1052 - accuracy: 0.5333 - val_loss: 1.1317 - val_accuracy: 0.5300\n",
            "Epoch 27/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 1.1023 - accuracy: 0.5378 - val_loss: 1.1273 - val_accuracy: 0.5300\n",
            "Epoch 28/10000\n",
            "900/900 [==============================] - 0s 48us/step - loss: 1.0971 - accuracy: 0.5333 - val_loss: 1.1298 - val_accuracy: 0.5300\n",
            "Epoch 29/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 1.0963 - accuracy: 0.5344 - val_loss: 1.1227 - val_accuracy: 0.5300\n",
            "Epoch 30/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 1.0900 - accuracy: 0.5333 - val_loss: 1.1172 - val_accuracy: 0.5300\n",
            "Epoch 31/10000\n",
            "900/900 [==============================] - 0s 48us/step - loss: 1.0865 - accuracy: 0.5333 - val_loss: 1.1195 - val_accuracy: 0.5300\n",
            "Epoch 32/10000\n",
            "900/900 [==============================] - 0s 55us/step - loss: 1.0820 - accuracy: 0.5333 - val_loss: 1.1115 - val_accuracy: 0.5300\n",
            "Epoch 33/10000\n",
            "900/900 [==============================] - 0s 48us/step - loss: 1.0789 - accuracy: 0.5344 - val_loss: 1.1119 - val_accuracy: 0.5300\n",
            "Epoch 34/10000\n",
            "900/900 [==============================] - 0s 55us/step - loss: 1.0799 - accuracy: 0.5333 - val_loss: 1.1016 - val_accuracy: 0.5300\n",
            "Epoch 35/10000\n",
            "900/900 [==============================] - 0s 55us/step - loss: 1.0765 - accuracy: 0.5344 - val_loss: 1.1017 - val_accuracy: 0.5300\n",
            "Epoch 36/10000\n",
            "900/900 [==============================] - 0s 57us/step - loss: 1.0667 - accuracy: 0.5333 - val_loss: 1.1007 - val_accuracy: 0.5300\n",
            "Epoch 37/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 1.0679 - accuracy: 0.5333 - val_loss: 1.0949 - val_accuracy: 0.5300\n",
            "Epoch 38/10000\n",
            "900/900 [==============================] - 0s 58us/step - loss: 1.0636 - accuracy: 0.5356 - val_loss: 1.0910 - val_accuracy: 0.5300\n",
            "Epoch 39/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 1.0592 - accuracy: 0.5367 - val_loss: 1.0873 - val_accuracy: 0.5300\n",
            "Epoch 40/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 1.0561 - accuracy: 0.5367 - val_loss: 1.0909 - val_accuracy: 0.5300\n",
            "Epoch 41/10000\n",
            "900/900 [==============================] - 0s 54us/step - loss: 1.0524 - accuracy: 0.5367 - val_loss: 1.0852 - val_accuracy: 0.5300\n",
            "Epoch 42/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 1.0465 - accuracy: 0.5344 - val_loss: 1.0745 - val_accuracy: 0.5300\n",
            "Epoch 43/10000\n",
            "900/900 [==============================] - 0s 46us/step - loss: 1.0488 - accuracy: 0.5378 - val_loss: 1.0847 - val_accuracy: 0.5300\n",
            "Epoch 44/10000\n",
            "900/900 [==============================] - 0s 48us/step - loss: 1.0487 - accuracy: 0.5333 - val_loss: 1.0645 - val_accuracy: 0.5300\n",
            "Epoch 45/10000\n",
            "900/900 [==============================] - 0s 59us/step - loss: 1.0430 - accuracy: 0.5333 - val_loss: 1.0634 - val_accuracy: 0.5300\n",
            "Epoch 46/10000\n",
            "900/900 [==============================] - 0s 54us/step - loss: 1.0350 - accuracy: 0.5344 - val_loss: 1.0764 - val_accuracy: 0.5300\n",
            "Epoch 47/10000\n",
            "900/900 [==============================] - 0s 48us/step - loss: 1.0369 - accuracy: 0.5333 - val_loss: 1.0597 - val_accuracy: 0.5300\n",
            "Epoch 48/10000\n",
            "900/900 [==============================] - 0s 54us/step - loss: 1.0263 - accuracy: 0.5389 - val_loss: 1.0561 - val_accuracy: 0.5300\n",
            "Epoch 49/10000\n",
            "900/900 [==============================] - 0s 57us/step - loss: 1.0201 - accuracy: 0.5344 - val_loss: 1.0560 - val_accuracy: 0.5300\n",
            "Epoch 50/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 1.0206 - accuracy: 0.5378 - val_loss: 1.0579 - val_accuracy: 0.5600\n",
            "Epoch 51/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 1.0270 - accuracy: 0.5622 - val_loss: 1.0395 - val_accuracy: 0.5300\n",
            "Epoch 52/10000\n",
            "900/900 [==============================] - 0s 61us/step - loss: 1.0077 - accuracy: 0.5356 - val_loss: 1.0363 - val_accuracy: 0.5300\n",
            "Epoch 53/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 1.0012 - accuracy: 0.5567 - val_loss: 1.0290 - val_accuracy: 0.5300\n",
            "Epoch 54/10000\n",
            "900/900 [==============================] - 0s 55us/step - loss: 0.9965 - accuracy: 0.5467 - val_loss: 1.0341 - val_accuracy: 0.5300\n",
            "Epoch 55/10000\n",
            "900/900 [==============================] - 0s 55us/step - loss: 0.9946 - accuracy: 0.5400 - val_loss: 1.0237 - val_accuracy: 0.5400\n",
            "Epoch 56/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.9927 - accuracy: 0.5589 - val_loss: 1.0277 - val_accuracy: 0.5300\n",
            "Epoch 57/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.9877 - accuracy: 0.5467 - val_loss: 1.0171 - val_accuracy: 0.5400\n",
            "Epoch 58/10000\n",
            "900/900 [==============================] - 0s 57us/step - loss: 0.9819 - accuracy: 0.5511 - val_loss: 1.0096 - val_accuracy: 0.5300\n",
            "Epoch 59/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.9740 - accuracy: 0.5489 - val_loss: 0.9956 - val_accuracy: 0.5400\n",
            "Epoch 60/10000\n",
            "900/900 [==============================] - 0s 54us/step - loss: 0.9661 - accuracy: 0.5667 - val_loss: 0.9916 - val_accuracy: 0.5400\n",
            "Epoch 61/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.9641 - accuracy: 0.5667 - val_loss: 0.9901 - val_accuracy: 0.5500\n",
            "Epoch 62/10000\n",
            "900/900 [==============================] - 0s 56us/step - loss: 0.9583 - accuracy: 0.5711 - val_loss: 0.9972 - val_accuracy: 0.5300\n",
            "Epoch 63/10000\n",
            "900/900 [==============================] - 0s 60us/step - loss: 0.9587 - accuracy: 0.5522 - val_loss: 0.9726 - val_accuracy: 0.5500\n",
            "Epoch 64/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.9565 - accuracy: 0.5722 - val_loss: 0.9757 - val_accuracy: 0.5300\n",
            "Epoch 65/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.9493 - accuracy: 0.5644 - val_loss: 0.9797 - val_accuracy: 0.5300\n",
            "Epoch 66/10000\n",
            "900/900 [==============================] - 0s 57us/step - loss: 0.9443 - accuracy: 0.5611 - val_loss: 0.9727 - val_accuracy: 0.5400\n",
            "Epoch 67/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.9406 - accuracy: 0.5589 - val_loss: 0.9638 - val_accuracy: 0.5300\n",
            "Epoch 68/10000\n",
            "900/900 [==============================] - 0s 54us/step - loss: 0.9357 - accuracy: 0.5644 - val_loss: 0.9614 - val_accuracy: 0.5400\n",
            "Epoch 69/10000\n",
            "900/900 [==============================] - 0s 74us/step - loss: 0.9307 - accuracy: 0.5778 - val_loss: 0.9519 - val_accuracy: 0.5300\n",
            "Epoch 70/10000\n",
            "900/900 [==============================] - 0s 69us/step - loss: 0.9194 - accuracy: 0.5756 - val_loss: 0.9497 - val_accuracy: 0.5300\n",
            "Epoch 71/10000\n",
            "900/900 [==============================] - 0s 64us/step - loss: 0.9254 - accuracy: 0.5644 - val_loss: 0.9478 - val_accuracy: 0.5300\n",
            "Epoch 72/10000\n",
            "900/900 [==============================] - 0s 64us/step - loss: 0.9231 - accuracy: 0.5633 - val_loss: 0.9354 - val_accuracy: 0.5400\n",
            "Epoch 73/10000\n",
            "900/900 [==============================] - 0s 64us/step - loss: 0.9100 - accuracy: 0.5878 - val_loss: 0.9344 - val_accuracy: 0.5400\n",
            "Epoch 74/10000\n",
            "900/900 [==============================] - 0s 61us/step - loss: 0.9105 - accuracy: 0.6011 - val_loss: 0.9332 - val_accuracy: 0.5400\n",
            "Epoch 75/10000\n",
            "900/900 [==============================] - 0s 62us/step - loss: 0.9005 - accuracy: 0.5789 - val_loss: 0.9433 - val_accuracy: 0.5300\n",
            "Epoch 76/10000\n",
            "900/900 [==============================] - 0s 57us/step - loss: 0.8957 - accuracy: 0.5600 - val_loss: 0.9252 - val_accuracy: 0.5800\n",
            "Epoch 77/10000\n",
            "900/900 [==============================] - 0s 63us/step - loss: 0.8989 - accuracy: 0.6133 - val_loss: 0.9394 - val_accuracy: 0.5300\n",
            "Epoch 78/10000\n",
            "900/900 [==============================] - 0s 73us/step - loss: 0.8888 - accuracy: 0.5900 - val_loss: 0.9023 - val_accuracy: 0.5400\n",
            "Epoch 79/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.8750 - accuracy: 0.6089 - val_loss: 0.9260 - val_accuracy: 0.5300\n",
            "Epoch 80/10000\n",
            "900/900 [==============================] - 0s 58us/step - loss: 0.8789 - accuracy: 0.5756 - val_loss: 0.8955 - val_accuracy: 0.5500\n",
            "Epoch 81/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.8656 - accuracy: 0.6211 - val_loss: 0.9493 - val_accuracy: 0.5300\n",
            "Epoch 82/10000\n",
            "900/900 [==============================] - 0s 62us/step - loss: 0.8774 - accuracy: 0.5856 - val_loss: 0.8853 - val_accuracy: 0.5600\n",
            "Epoch 83/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.8633 - accuracy: 0.6033 - val_loss: 0.9043 - val_accuracy: 0.5300\n",
            "Epoch 84/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.8634 - accuracy: 0.6033 - val_loss: 0.8768 - val_accuracy: 0.5300\n",
            "Epoch 85/10000\n",
            "900/900 [==============================] - 0s 54us/step - loss: 0.8601 - accuracy: 0.6178 - val_loss: 0.8750 - val_accuracy: 0.5700\n",
            "Epoch 86/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.8492 - accuracy: 0.6178 - val_loss: 0.8749 - val_accuracy: 0.5400\n",
            "Epoch 87/10000\n",
            "900/900 [==============================] - 0s 54us/step - loss: 0.8470 - accuracy: 0.6078 - val_loss: 0.8624 - val_accuracy: 0.5700\n",
            "Epoch 88/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.8409 - accuracy: 0.6344 - val_loss: 0.8592 - val_accuracy: 0.5400\n",
            "Epoch 89/10000\n",
            "900/900 [==============================] - 0s 48us/step - loss: 0.8328 - accuracy: 0.6356 - val_loss: 0.8836 - val_accuracy: 0.5400\n",
            "Epoch 90/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.8349 - accuracy: 0.6011 - val_loss: 0.8769 - val_accuracy: 0.5300\n",
            "Epoch 91/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.8313 - accuracy: 0.6111 - val_loss: 0.8705 - val_accuracy: 0.5400\n",
            "Epoch 92/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.8221 - accuracy: 0.6322 - val_loss: 0.8803 - val_accuracy: 0.5400\n",
            "Epoch 93/10000\n",
            "900/900 [==============================] - 0s 48us/step - loss: 0.8200 - accuracy: 0.6233 - val_loss: 0.8394 - val_accuracy: 0.5800\n",
            "Epoch 94/10000\n",
            "900/900 [==============================] - 0s 55us/step - loss: 0.8150 - accuracy: 0.6600 - val_loss: 0.8418 - val_accuracy: 0.5700\n",
            "Epoch 95/10000\n",
            "900/900 [==============================] - 0s 56us/step - loss: 0.8081 - accuracy: 0.6556 - val_loss: 0.8302 - val_accuracy: 0.5400\n",
            "Epoch 96/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.7978 - accuracy: 0.6478 - val_loss: 0.8386 - val_accuracy: 0.5300\n",
            "Epoch 97/10000\n",
            "900/900 [==============================] - 0s 48us/step - loss: 0.7942 - accuracy: 0.6478 - val_loss: 0.8149 - val_accuracy: 0.5900\n",
            "Epoch 98/10000\n",
            "900/900 [==============================] - 0s 59us/step - loss: 0.7939 - accuracy: 0.6678 - val_loss: 0.8177 - val_accuracy: 0.5500\n",
            "Epoch 99/10000\n",
            "900/900 [==============================] - 0s 57us/step - loss: 0.7896 - accuracy: 0.6656 - val_loss: 0.8372 - val_accuracy: 0.5400\n",
            "Epoch 100/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.7854 - accuracy: 0.6400 - val_loss: 0.8305 - val_accuracy: 0.5400\n",
            "Epoch 101/10000\n",
            "900/900 [==============================] - 0s 60us/step - loss: 0.7815 - accuracy: 0.6400 - val_loss: 0.8065 - val_accuracy: 0.6000\n",
            "Epoch 102/10000\n",
            "900/900 [==============================] - 0s 79us/step - loss: 0.7774 - accuracy: 0.6822 - val_loss: 0.7900 - val_accuracy: 0.6000\n",
            "Epoch 103/10000\n",
            "900/900 [==============================] - 0s 62us/step - loss: 0.7784 - accuracy: 0.6844 - val_loss: 0.7986 - val_accuracy: 0.6400\n",
            "Epoch 104/10000\n",
            "900/900 [==============================] - 0s 61us/step - loss: 0.7744 - accuracy: 0.6978 - val_loss: 0.8178 - val_accuracy: 0.5400\n",
            "Epoch 105/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.7623 - accuracy: 0.6611 - val_loss: 0.8016 - val_accuracy: 0.5600\n",
            "Epoch 106/10000\n",
            "900/900 [==============================] - 0s 56us/step - loss: 0.7570 - accuracy: 0.6789 - val_loss: 0.7884 - val_accuracy: 0.5600\n",
            "Epoch 107/10000\n",
            "900/900 [==============================] - 0s 54us/step - loss: 0.7538 - accuracy: 0.6789 - val_loss: 0.7666 - val_accuracy: 0.6300\n",
            "Epoch 108/10000\n",
            "900/900 [==============================] - 0s 55us/step - loss: 0.7531 - accuracy: 0.7389 - val_loss: 0.7971 - val_accuracy: 0.5500\n",
            "Epoch 109/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.7480 - accuracy: 0.6789 - val_loss: 0.7679 - val_accuracy: 0.6100\n",
            "Epoch 110/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.7401 - accuracy: 0.7267 - val_loss: 0.7519 - val_accuracy: 0.6200\n",
            "Epoch 111/10000\n",
            "900/900 [==============================] - 0s 57us/step - loss: 0.7362 - accuracy: 0.7322 - val_loss: 0.8108 - val_accuracy: 0.5400\n",
            "Epoch 112/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.7378 - accuracy: 0.6756 - val_loss: 0.7460 - val_accuracy: 0.7000\n",
            "Epoch 113/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.7274 - accuracy: 0.7289 - val_loss: 0.7470 - val_accuracy: 0.5800\n",
            "Epoch 114/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.7227 - accuracy: 0.7067 - val_loss: 0.7419 - val_accuracy: 0.7000\n",
            "Epoch 115/10000\n",
            "900/900 [==============================] - 0s 48us/step - loss: 0.7203 - accuracy: 0.7489 - val_loss: 0.7416 - val_accuracy: 0.7100\n",
            "Epoch 116/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.7176 - accuracy: 0.7778 - val_loss: 0.7271 - val_accuracy: 0.6700\n",
            "Epoch 117/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.7037 - accuracy: 0.7456 - val_loss: 0.7401 - val_accuracy: 0.5700\n",
            "Epoch 118/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.7115 - accuracy: 0.7089 - val_loss: 0.7478 - val_accuracy: 0.5800\n",
            "Epoch 119/10000\n",
            "900/900 [==============================] - 0s 59us/step - loss: 0.7005 - accuracy: 0.7289 - val_loss: 0.7224 - val_accuracy: 0.6300\n",
            "Epoch 120/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.6899 - accuracy: 0.7611 - val_loss: 0.7197 - val_accuracy: 0.7100\n",
            "Epoch 121/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.6989 - accuracy: 0.7489 - val_loss: 0.7571 - val_accuracy: 0.5600\n",
            "Epoch 122/10000\n",
            "900/900 [==============================] - 0s 55us/step - loss: 0.6843 - accuracy: 0.7322 - val_loss: 0.7117 - val_accuracy: 0.6000\n",
            "Epoch 123/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.6857 - accuracy: 0.7533 - val_loss: 0.6959 - val_accuracy: 0.6700\n",
            "Epoch 124/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.6834 - accuracy: 0.7589 - val_loss: 0.6936 - val_accuracy: 0.6900\n",
            "Epoch 125/10000\n",
            "900/900 [==============================] - 0s 64us/step - loss: 0.6760 - accuracy: 0.7933 - val_loss: 0.6916 - val_accuracy: 0.6600\n",
            "Epoch 126/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.6710 - accuracy: 0.7667 - val_loss: 0.7304 - val_accuracy: 0.5700\n",
            "Epoch 127/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.6612 - accuracy: 0.7400 - val_loss: 0.6861 - val_accuracy: 0.6400\n",
            "Epoch 128/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.6494 - accuracy: 0.8089 - val_loss: 0.6970 - val_accuracy: 0.6100\n",
            "Epoch 129/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.6576 - accuracy: 0.7633 - val_loss: 0.7039 - val_accuracy: 0.5800\n",
            "Epoch 130/10000\n",
            "900/900 [==============================] - 0s 58us/step - loss: 0.6515 - accuracy: 0.7456 - val_loss: 0.6804 - val_accuracy: 0.6800\n",
            "Epoch 131/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.6493 - accuracy: 0.7589 - val_loss: 0.7268 - val_accuracy: 0.5600\n",
            "Epoch 132/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.6532 - accuracy: 0.7289 - val_loss: 0.6556 - val_accuracy: 0.7300\n",
            "Epoch 133/10000\n",
            "900/900 [==============================] - 0s 57us/step - loss: 0.6314 - accuracy: 0.8133 - val_loss: 0.6652 - val_accuracy: 0.6500\n",
            "Epoch 134/10000\n",
            "900/900 [==============================] - 0s 68us/step - loss: 0.6364 - accuracy: 0.7867 - val_loss: 0.6828 - val_accuracy: 0.6800\n",
            "Epoch 135/10000\n",
            "900/900 [==============================] - 0s 61us/step - loss: 0.6302 - accuracy: 0.7956 - val_loss: 0.6751 - val_accuracy: 0.7000\n",
            "Epoch 136/10000\n",
            "900/900 [==============================] - 0s 55us/step - loss: 0.6295 - accuracy: 0.7878 - val_loss: 0.6591 - val_accuracy: 0.6900\n",
            "Epoch 137/10000\n",
            "900/900 [==============================] - 0s 55us/step - loss: 0.6242 - accuracy: 0.7878 - val_loss: 0.6388 - val_accuracy: 0.7300\n",
            "Epoch 138/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.6226 - accuracy: 0.8233 - val_loss: 0.6566 - val_accuracy: 0.6200\n",
            "Epoch 139/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.6187 - accuracy: 0.7900 - val_loss: 0.6611 - val_accuracy: 0.7000\n",
            "Epoch 140/10000\n",
            "900/900 [==============================] - 0s 56us/step - loss: 0.6095 - accuracy: 0.8167 - val_loss: 0.6489 - val_accuracy: 0.6800\n",
            "Epoch 141/10000\n",
            "900/900 [==============================] - 0s 61us/step - loss: 0.5957 - accuracy: 0.8289 - val_loss: 0.6748 - val_accuracy: 0.6200\n",
            "Epoch 142/10000\n",
            "900/900 [==============================] - 0s 55us/step - loss: 0.6073 - accuracy: 0.7978 - val_loss: 0.6727 - val_accuracy: 0.6100\n",
            "Epoch 143/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.6035 - accuracy: 0.8033 - val_loss: 0.6382 - val_accuracy: 0.7200\n",
            "Epoch 144/10000\n",
            "900/900 [==============================] - 0s 47us/step - loss: 0.6038 - accuracy: 0.8067 - val_loss: 0.6365 - val_accuracy: 0.7200\n",
            "Epoch 145/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.5918 - accuracy: 0.8167 - val_loss: 0.6327 - val_accuracy: 0.7000\n",
            "Epoch 146/10000\n",
            "900/900 [==============================] - 0s 58us/step - loss: 0.5959 - accuracy: 0.8189 - val_loss: 0.6182 - val_accuracy: 0.7000\n",
            "Epoch 147/10000\n",
            "900/900 [==============================] - 0s 55us/step - loss: 0.5832 - accuracy: 0.8456 - val_loss: 0.6229 - val_accuracy: 0.6800\n",
            "Epoch 148/10000\n",
            "900/900 [==============================] - 0s 48us/step - loss: 0.5696 - accuracy: 0.8444 - val_loss: 0.6225 - val_accuracy: 0.6900\n",
            "Epoch 149/10000\n",
            "900/900 [==============================] - 0s 57us/step - loss: 0.5776 - accuracy: 0.8200 - val_loss: 0.6476 - val_accuracy: 0.6100\n",
            "Epoch 150/10000\n",
            "900/900 [==============================] - 0s 54us/step - loss: 0.5654 - accuracy: 0.8156 - val_loss: 0.6280 - val_accuracy: 0.6300\n",
            "Epoch 151/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.5628 - accuracy: 0.8367 - val_loss: 0.6120 - val_accuracy: 0.6800\n",
            "Epoch 152/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.5663 - accuracy: 0.8444 - val_loss: 0.5796 - val_accuracy: 0.7400\n",
            "Epoch 153/10000\n",
            "900/900 [==============================] - 0s 55us/step - loss: 0.5616 - accuracy: 0.8444 - val_loss: 0.6114 - val_accuracy: 0.6900\n",
            "Epoch 154/10000\n",
            "900/900 [==============================] - 0s 66us/step - loss: 0.5517 - accuracy: 0.8389 - val_loss: 0.5708 - val_accuracy: 0.8100\n",
            "Epoch 155/10000\n",
            "900/900 [==============================] - 0s 55us/step - loss: 0.5519 - accuracy: 0.8522 - val_loss: 0.6165 - val_accuracy: 0.6400\n",
            "Epoch 156/10000\n",
            "900/900 [==============================] - 0s 54us/step - loss: 0.5453 - accuracy: 0.8156 - val_loss: 0.5943 - val_accuracy: 0.6700\n",
            "Epoch 157/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.5445 - accuracy: 0.8333 - val_loss: 0.5845 - val_accuracy: 0.7200\n",
            "Epoch 158/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.5337 - accuracy: 0.8667 - val_loss: 0.5908 - val_accuracy: 0.7000\n",
            "Epoch 159/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.5290 - accuracy: 0.8678 - val_loss: 0.5649 - val_accuracy: 0.7700\n",
            "Epoch 160/10000\n",
            "900/900 [==============================] - 0s 60us/step - loss: 0.5330 - accuracy: 0.8556 - val_loss: 0.5919 - val_accuracy: 0.6900\n",
            "Epoch 161/10000\n",
            "900/900 [==============================] - 0s 56us/step - loss: 0.5273 - accuracy: 0.8356 - val_loss: 0.5979 - val_accuracy: 0.6600\n",
            "Epoch 162/10000\n",
            "900/900 [==============================] - 0s 54us/step - loss: 0.5192 - accuracy: 0.8433 - val_loss: 0.5807 - val_accuracy: 0.6900\n",
            "Epoch 163/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.5203 - accuracy: 0.8600 - val_loss: 0.5714 - val_accuracy: 0.7200\n",
            "Epoch 164/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.5127 - accuracy: 0.8633 - val_loss: 0.5823 - val_accuracy: 0.6700\n",
            "Epoch 165/10000\n",
            "900/900 [==============================] - 0s 54us/step - loss: 0.5101 - accuracy: 0.8578 - val_loss: 0.5335 - val_accuracy: 0.8300\n",
            "Epoch 166/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.5028 - accuracy: 0.8867 - val_loss: 0.5376 - val_accuracy: 0.7600\n",
            "Epoch 167/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.5030 - accuracy: 0.9044 - val_loss: 0.5339 - val_accuracy: 0.7100\n",
            "Epoch 168/10000\n",
            "900/900 [==============================] - 0s 58us/step - loss: 0.4878 - accuracy: 0.8967 - val_loss: 0.6144 - val_accuracy: 0.6000\n",
            "Epoch 169/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.4921 - accuracy: 0.8611 - val_loss: 0.5257 - val_accuracy: 0.8400\n",
            "Epoch 170/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.5000 - accuracy: 0.8756 - val_loss: 0.5137 - val_accuracy: 0.8200\n",
            "Epoch 171/10000\n",
            "900/900 [==============================] - 0s 58us/step - loss: 0.4852 - accuracy: 0.8956 - val_loss: 0.5419 - val_accuracy: 0.7900\n",
            "Epoch 172/10000\n",
            "900/900 [==============================] - 0s 55us/step - loss: 0.4945 - accuracy: 0.8800 - val_loss: 0.5092 - val_accuracy: 0.8700\n",
            "Epoch 173/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.4803 - accuracy: 0.8889 - val_loss: 0.5119 - val_accuracy: 0.7800\n",
            "Epoch 174/10000\n",
            "900/900 [==============================] - 0s 54us/step - loss: 0.4822 - accuracy: 0.8911 - val_loss: 0.4967 - val_accuracy: 0.8300\n",
            "Epoch 175/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.4701 - accuracy: 0.9056 - val_loss: 0.5128 - val_accuracy: 0.7700\n",
            "Epoch 176/10000\n",
            "900/900 [==============================] - 0s 57us/step - loss: 0.4696 - accuracy: 0.8956 - val_loss: 0.5022 - val_accuracy: 0.8300\n",
            "Epoch 177/10000\n",
            "900/900 [==============================] - 0s 54us/step - loss: 0.4597 - accuracy: 0.8978 - val_loss: 0.5451 - val_accuracy: 0.7300\n",
            "Epoch 178/10000\n",
            "900/900 [==============================] - 0s 65us/step - loss: 0.4621 - accuracy: 0.8856 - val_loss: 0.5322 - val_accuracy: 0.7100\n",
            "Epoch 179/10000\n",
            "900/900 [==============================] - 0s 59us/step - loss: 0.4571 - accuracy: 0.8878 - val_loss: 0.5064 - val_accuracy: 0.7600\n",
            "Epoch 180/10000\n",
            "900/900 [==============================] - 0s 47us/step - loss: 0.4470 - accuracy: 0.9089 - val_loss: 0.5072 - val_accuracy: 0.8100\n",
            "Epoch 181/10000\n",
            "900/900 [==============================] - 0s 48us/step - loss: 0.4545 - accuracy: 0.8867 - val_loss: 0.4716 - val_accuracy: 0.8600\n",
            "Epoch 182/10000\n",
            "900/900 [==============================] - 0s 48us/step - loss: 0.4511 - accuracy: 0.8856 - val_loss: 0.4788 - val_accuracy: 0.8400\n",
            "Epoch 183/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.4396 - accuracy: 0.9144 - val_loss: 0.5184 - val_accuracy: 0.7100\n",
            "Epoch 184/10000\n",
            "900/900 [==============================] - 0s 60us/step - loss: 0.4372 - accuracy: 0.8900 - val_loss: 0.4610 - val_accuracy: 0.8500\n",
            "Epoch 185/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.4275 - accuracy: 0.9100 - val_loss: 0.4636 - val_accuracy: 0.8200\n",
            "Epoch 186/10000\n",
            "900/900 [==============================] - 0s 55us/step - loss: 0.4331 - accuracy: 0.9156 - val_loss: 0.5143 - val_accuracy: 0.7300\n",
            "Epoch 187/10000\n",
            "900/900 [==============================] - 0s 46us/step - loss: 0.4331 - accuracy: 0.9000 - val_loss: 0.5051 - val_accuracy: 0.7200\n",
            "Epoch 188/10000\n",
            "900/900 [==============================] - 0s 56us/step - loss: 0.4324 - accuracy: 0.9000 - val_loss: 0.4695 - val_accuracy: 0.7900\n",
            "Epoch 189/10000\n",
            "900/900 [==============================] - 0s 59us/step - loss: 0.4271 - accuracy: 0.9111 - val_loss: 0.4623 - val_accuracy: 0.7700\n",
            "Epoch 190/10000\n",
            "900/900 [==============================] - 0s 55us/step - loss: 0.4223 - accuracy: 0.9167 - val_loss: 0.4835 - val_accuracy: 0.7500\n",
            "Epoch 191/10000\n",
            "900/900 [==============================] - 0s 54us/step - loss: 0.4245 - accuracy: 0.9078 - val_loss: 0.4375 - val_accuracy: 0.8700\n",
            "Epoch 192/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.4241 - accuracy: 0.9189 - val_loss: 0.4360 - val_accuracy: 0.9000\n",
            "Epoch 193/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.4200 - accuracy: 0.9067 - val_loss: 0.4201 - val_accuracy: 0.9100\n",
            "Epoch 194/10000\n",
            "900/900 [==============================] - 0s 54us/step - loss: 0.4138 - accuracy: 0.9289 - val_loss: 0.5133 - val_accuracy: 0.7100\n",
            "Epoch 195/10000\n",
            "900/900 [==============================] - 0s 62us/step - loss: 0.4039 - accuracy: 0.9067 - val_loss: 0.4949 - val_accuracy: 0.7400\n",
            "Epoch 196/10000\n",
            "900/900 [==============================] - 0s 55us/step - loss: 0.4012 - accuracy: 0.9078 - val_loss: 0.4394 - val_accuracy: 0.8100\n",
            "Epoch 197/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.4011 - accuracy: 0.9122 - val_loss: 0.4352 - val_accuracy: 0.8300\n",
            "Epoch 198/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.3928 - accuracy: 0.9267 - val_loss: 0.4188 - val_accuracy: 0.8700\n",
            "Epoch 199/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.4011 - accuracy: 0.9167 - val_loss: 0.4401 - val_accuracy: 0.8600\n",
            "Epoch 200/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.3832 - accuracy: 0.9356 - val_loss: 0.4101 - val_accuracy: 0.8800\n",
            "Epoch 201/10000\n",
            "900/900 [==============================] - 0s 57us/step - loss: 0.3766 - accuracy: 0.9356 - val_loss: 0.4040 - val_accuracy: 0.9100\n",
            "Epoch 202/10000\n",
            "900/900 [==============================] - 0s 61us/step - loss: 0.3877 - accuracy: 0.9244 - val_loss: 0.4061 - val_accuracy: 0.8800\n",
            "Epoch 203/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.3817 - accuracy: 0.9389 - val_loss: 0.4687 - val_accuracy: 0.7600\n",
            "Epoch 204/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.3857 - accuracy: 0.9189 - val_loss: 0.4869 - val_accuracy: 0.7200\n",
            "Epoch 205/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.3789 - accuracy: 0.9189 - val_loss: 0.5228 - val_accuracy: 0.7000\n",
            "Epoch 206/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.3858 - accuracy: 0.8944 - val_loss: 0.3886 - val_accuracy: 0.8700\n",
            "Epoch 207/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.3753 - accuracy: 0.9322 - val_loss: 0.4161 - val_accuracy: 0.8400\n",
            "Epoch 208/10000\n",
            "900/900 [==============================] - 0s 63us/step - loss: 0.3627 - accuracy: 0.9289 - val_loss: 0.4113 - val_accuracy: 0.8200\n",
            "Epoch 209/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.3766 - accuracy: 0.9222 - val_loss: 0.3947 - val_accuracy: 0.9000\n",
            "Epoch 210/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.3588 - accuracy: 0.9422 - val_loss: 0.3954 - val_accuracy: 0.8700\n",
            "Epoch 211/10000\n",
            "900/900 [==============================] - 0s 54us/step - loss: 0.3578 - accuracy: 0.9233 - val_loss: 0.3732 - val_accuracy: 0.9300\n",
            "Epoch 212/10000\n",
            "900/900 [==============================] - 0s 55us/step - loss: 0.3702 - accuracy: 0.9367 - val_loss: 0.3819 - val_accuracy: 0.9300\n",
            "Epoch 213/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.3482 - accuracy: 0.9389 - val_loss: 0.4033 - val_accuracy: 0.8300\n",
            "Epoch 214/10000\n",
            "900/900 [==============================] - 0s 56us/step - loss: 0.3472 - accuracy: 0.9289 - val_loss: 0.3970 - val_accuracy: 0.8700\n",
            "Epoch 215/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.3615 - accuracy: 0.9200 - val_loss: 0.4373 - val_accuracy: 0.8000\n",
            "Epoch 216/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.3509 - accuracy: 0.9333 - val_loss: 0.3897 - val_accuracy: 0.9200\n",
            "Epoch 217/10000\n",
            "900/900 [==============================] - 0s 57us/step - loss: 0.3443 - accuracy: 0.9333 - val_loss: 0.3761 - val_accuracy: 0.8800\n",
            "Epoch 218/10000\n",
            "900/900 [==============================] - 0s 54us/step - loss: 0.3371 - accuracy: 0.9444 - val_loss: 0.3911 - val_accuracy: 0.8500\n",
            "Epoch 219/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.3425 - accuracy: 0.9389 - val_loss: 0.4157 - val_accuracy: 0.7900\n",
            "Epoch 220/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.3434 - accuracy: 0.9278 - val_loss: 0.3870 - val_accuracy: 0.8300\n",
            "Epoch 221/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.3152 - accuracy: 0.9533 - val_loss: 0.4126 - val_accuracy: 0.7800\n",
            "Epoch 222/10000\n",
            "900/900 [==============================] - 0s 58us/step - loss: 0.3352 - accuracy: 0.9411 - val_loss: 0.3995 - val_accuracy: 0.8000\n",
            "Epoch 223/10000\n",
            "900/900 [==============================] - 0s 59us/step - loss: 0.3200 - accuracy: 0.9411 - val_loss: 0.4053 - val_accuracy: 0.7900\n",
            "Epoch 224/10000\n",
            "900/900 [==============================] - 0s 55us/step - loss: 0.3291 - accuracy: 0.9356 - val_loss: 0.4040 - val_accuracy: 0.8000\n",
            "Epoch 225/10000\n",
            "900/900 [==============================] - 0s 66us/step - loss: 0.3226 - accuracy: 0.9389 - val_loss: 0.3505 - val_accuracy: 0.9000\n",
            "Epoch 226/10000\n",
            "900/900 [==============================] - 0s 67us/step - loss: 0.3180 - accuracy: 0.9422 - val_loss: 0.3916 - val_accuracy: 0.8200\n",
            "Epoch 227/10000\n",
            "900/900 [==============================] - 0s 57us/step - loss: 0.3284 - accuracy: 0.9289 - val_loss: 0.3870 - val_accuracy: 0.8300\n",
            "Epoch 228/10000\n",
            "900/900 [==============================] - 0s 55us/step - loss: 0.3225 - accuracy: 0.9278 - val_loss: 0.3588 - val_accuracy: 0.8600\n",
            "Epoch 229/10000\n",
            "900/900 [==============================] - 0s 69us/step - loss: 0.3107 - accuracy: 0.9400 - val_loss: 0.3677 - val_accuracy: 0.8400\n",
            "Epoch 230/10000\n",
            "900/900 [==============================] - 0s 57us/step - loss: 0.3037 - accuracy: 0.9444 - val_loss: 0.3258 - val_accuracy: 0.9500\n",
            "Epoch 231/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.3010 - accuracy: 0.9500 - val_loss: 0.3460 - val_accuracy: 0.8600\n",
            "Epoch 232/10000\n",
            "900/900 [==============================] - 0s 55us/step - loss: 0.3057 - accuracy: 0.9511 - val_loss: 0.3610 - val_accuracy: 0.8500\n",
            "Epoch 233/10000\n",
            "900/900 [==============================] - 0s 59us/step - loss: 0.3009 - accuracy: 0.9444 - val_loss: 0.3592 - val_accuracy: 0.8800\n",
            "Epoch 234/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.3056 - accuracy: 0.9422 - val_loss: 0.3311 - val_accuracy: 0.9300\n",
            "Epoch 235/10000\n",
            "900/900 [==============================] - 0s 67us/step - loss: 0.3009 - accuracy: 0.9356 - val_loss: 0.2995 - val_accuracy: 0.9500\n",
            "Epoch 236/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.2893 - accuracy: 0.9489 - val_loss: 0.3338 - val_accuracy: 0.8900\n",
            "Epoch 237/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.2901 - accuracy: 0.9489 - val_loss: 0.4178 - val_accuracy: 0.7700\n",
            "Epoch 238/10000\n",
            "900/900 [==============================] - 0s 56us/step - loss: 0.2906 - accuracy: 0.9400 - val_loss: 0.3270 - val_accuracy: 0.9000\n",
            "Epoch 239/10000\n",
            "900/900 [==============================] - 0s 54us/step - loss: 0.2748 - accuracy: 0.9544 - val_loss: 0.3300 - val_accuracy: 0.8900\n",
            "Epoch 240/10000\n",
            "900/900 [==============================] - 0s 60us/step - loss: 0.2762 - accuracy: 0.9589 - val_loss: 0.2868 - val_accuracy: 0.9500\n",
            "Epoch 241/10000\n",
            "900/900 [==============================] - 0s 54us/step - loss: 0.2849 - accuracy: 0.9544 - val_loss: 0.3239 - val_accuracy: 0.8800\n",
            "Epoch 242/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.2770 - accuracy: 0.9522 - val_loss: 0.3582 - val_accuracy: 0.8400\n",
            "Epoch 243/10000\n",
            "900/900 [==============================] - 0s 62us/step - loss: 0.2745 - accuracy: 0.9400 - val_loss: 0.3613 - val_accuracy: 0.8500\n",
            "Epoch 244/10000\n",
            "900/900 [==============================] - 0s 64us/step - loss: 0.2816 - accuracy: 0.9456 - val_loss: 0.3460 - val_accuracy: 0.8500\n",
            "Epoch 245/10000\n",
            "900/900 [==============================] - 0s 59us/step - loss: 0.2717 - accuracy: 0.9556 - val_loss: 0.3410 - val_accuracy: 0.8500\n",
            "Epoch 246/10000\n",
            "900/900 [==============================] - 0s 56us/step - loss: 0.2854 - accuracy: 0.9389 - val_loss: 0.2743 - val_accuracy: 0.9500\n",
            "Epoch 247/10000\n",
            "900/900 [==============================] - 0s 65us/step - loss: 0.2736 - accuracy: 0.9589 - val_loss: 0.3597 - val_accuracy: 0.8200\n",
            "Epoch 248/10000\n",
            "900/900 [==============================] - 0s 57us/step - loss: 0.2622 - accuracy: 0.9500 - val_loss: 0.2749 - val_accuracy: 0.9500\n",
            "Epoch 249/10000\n",
            "900/900 [==============================] - 0s 54us/step - loss: 0.2776 - accuracy: 0.9589 - val_loss: 0.2921 - val_accuracy: 0.9200\n",
            "Epoch 250/10000\n",
            "900/900 [==============================] - 0s 60us/step - loss: 0.2599 - accuracy: 0.9589 - val_loss: 0.3495 - val_accuracy: 0.8200\n",
            "Epoch 251/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.2630 - accuracy: 0.9433 - val_loss: 0.2913 - val_accuracy: 0.9300\n",
            "Epoch 252/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.2578 - accuracy: 0.9500 - val_loss: 0.3375 - val_accuracy: 0.8500\n",
            "Epoch 253/10000\n",
            "900/900 [==============================] - 0s 56us/step - loss: 0.2633 - accuracy: 0.9489 - val_loss: 0.2625 - val_accuracy: 0.9500\n",
            "Epoch 254/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.2536 - accuracy: 0.9633 - val_loss: 0.2639 - val_accuracy: 0.9500\n",
            "Epoch 255/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.2668 - accuracy: 0.9633 - val_loss: 0.2621 - val_accuracy: 0.9500\n",
            "Epoch 256/10000\n",
            "900/900 [==============================] - 0s 86us/step - loss: 0.2415 - accuracy: 0.9711 - val_loss: 0.2562 - val_accuracy: 0.9500\n",
            "Epoch 257/10000\n",
            "900/900 [==============================] - 0s 60us/step - loss: 0.2514 - accuracy: 0.9611 - val_loss: 0.2853 - val_accuracy: 0.9300\n",
            "Epoch 258/10000\n",
            "900/900 [==============================] - 0s 56us/step - loss: 0.2459 - accuracy: 0.9689 - val_loss: 0.2600 - val_accuracy: 0.9500\n",
            "Epoch 259/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.2571 - accuracy: 0.9656 - val_loss: 0.3552 - val_accuracy: 0.8300\n",
            "Epoch 260/10000\n",
            "900/900 [==============================] - 0s 58us/step - loss: 0.2525 - accuracy: 0.9467 - val_loss: 0.2796 - val_accuracy: 0.9200\n",
            "Epoch 261/10000\n",
            "900/900 [==============================] - 0s 55us/step - loss: 0.2487 - accuracy: 0.9589 - val_loss: 0.2453 - val_accuracy: 0.9600\n",
            "Epoch 262/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.2560 - accuracy: 0.9667 - val_loss: 0.3182 - val_accuracy: 0.8700\n",
            "Epoch 263/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.2369 - accuracy: 0.9633 - val_loss: 0.2821 - val_accuracy: 0.9200\n",
            "Epoch 264/10000\n",
            "900/900 [==============================] - 0s 62us/step - loss: 0.2213 - accuracy: 0.9667 - val_loss: 0.2545 - val_accuracy: 0.9500\n",
            "Epoch 265/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.2408 - accuracy: 0.9667 - val_loss: 0.2844 - val_accuracy: 0.9100\n",
            "Epoch 266/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.2292 - accuracy: 0.9656 - val_loss: 0.2825 - val_accuracy: 0.9000\n",
            "Epoch 267/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.2278 - accuracy: 0.9689 - val_loss: 0.3058 - val_accuracy: 0.8900\n",
            "Epoch 268/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.2301 - accuracy: 0.9611 - val_loss: 0.2767 - val_accuracy: 0.9100\n",
            "Epoch 269/10000\n",
            "900/900 [==============================] - 0s 66us/step - loss: 0.2312 - accuracy: 0.9556 - val_loss: 0.2611 - val_accuracy: 0.9300\n",
            "Epoch 270/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.2180 - accuracy: 0.9689 - val_loss: 0.2193 - val_accuracy: 0.9700\n",
            "Epoch 271/10000\n",
            "900/900 [==============================] - 0s 57us/step - loss: 0.2314 - accuracy: 0.9600 - val_loss: 0.2501 - val_accuracy: 0.9300\n",
            "Epoch 272/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.2263 - accuracy: 0.9656 - val_loss: 0.2553 - val_accuracy: 0.9200\n",
            "Epoch 273/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.2226 - accuracy: 0.9678 - val_loss: 0.2933 - val_accuracy: 0.8900\n",
            "Epoch 274/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.2119 - accuracy: 0.9644 - val_loss: 0.2285 - val_accuracy: 0.9500\n",
            "Epoch 275/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.2219 - accuracy: 0.9622 - val_loss: 0.2307 - val_accuracy: 0.9600\n",
            "Epoch 276/10000\n",
            "900/900 [==============================] - 0s 54us/step - loss: 0.2128 - accuracy: 0.9722 - val_loss: 0.2666 - val_accuracy: 0.9100\n",
            "Epoch 277/10000\n",
            "900/900 [==============================] - 0s 47us/step - loss: 0.2260 - accuracy: 0.9489 - val_loss: 0.2761 - val_accuracy: 0.9100\n",
            "Epoch 278/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.2143 - accuracy: 0.9633 - val_loss: 0.2587 - val_accuracy: 0.9300\n",
            "Epoch 279/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.2134 - accuracy: 0.9656 - val_loss: 0.2359 - val_accuracy: 0.9500\n",
            "Epoch 280/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.2271 - accuracy: 0.9600 - val_loss: 0.3170 - val_accuracy: 0.8300\n",
            "Epoch 281/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.2110 - accuracy: 0.9633 - val_loss: 0.2605 - val_accuracy: 0.9100\n",
            "Epoch 282/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.2171 - accuracy: 0.9611 - val_loss: 0.2502 - val_accuracy: 0.9200\n",
            "Epoch 283/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.2059 - accuracy: 0.9711 - val_loss: 0.2241 - val_accuracy: 0.9500\n",
            "Epoch 284/10000\n",
            "900/900 [==============================] - 0s 54us/step - loss: 0.2222 - accuracy: 0.9533 - val_loss: 0.2364 - val_accuracy: 0.9400\n",
            "Epoch 285/10000\n",
            "900/900 [==============================] - 0s 54us/step - loss: 0.1972 - accuracy: 0.9678 - val_loss: 0.2097 - val_accuracy: 0.9600\n",
            "Epoch 286/10000\n",
            "900/900 [==============================] - 0s 47us/step - loss: 0.2066 - accuracy: 0.9644 - val_loss: 0.2099 - val_accuracy: 0.9600\n",
            "Epoch 287/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.2054 - accuracy: 0.9756 - val_loss: 0.2512 - val_accuracy: 0.9000\n",
            "Epoch 288/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.1983 - accuracy: 0.9678 - val_loss: 0.2345 - val_accuracy: 0.9200\n",
            "Epoch 289/10000\n",
            "900/900 [==============================] - 0s 55us/step - loss: 0.1978 - accuracy: 0.9756 - val_loss: 0.2133 - val_accuracy: 0.9700\n",
            "Epoch 290/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.2011 - accuracy: 0.9678 - val_loss: 0.2012 - val_accuracy: 0.9700\n",
            "Epoch 291/10000\n",
            "900/900 [==============================] - 0s 47us/step - loss: 0.2043 - accuracy: 0.9700 - val_loss: 0.2758 - val_accuracy: 0.9100\n",
            "Epoch 292/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.1932 - accuracy: 0.9644 - val_loss: 0.2357 - val_accuracy: 0.9400\n",
            "Epoch 293/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.1880 - accuracy: 0.9767 - val_loss: 0.2349 - val_accuracy: 0.9500\n",
            "Epoch 294/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.1883 - accuracy: 0.9800 - val_loss: 0.1986 - val_accuracy: 0.9600\n",
            "Epoch 295/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.1873 - accuracy: 0.9711 - val_loss: 0.2011 - val_accuracy: 0.9600\n",
            "Epoch 296/10000\n",
            "900/900 [==============================] - 0s 48us/step - loss: 0.1919 - accuracy: 0.9700 - val_loss: 0.1999 - val_accuracy: 0.9400\n",
            "Epoch 297/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.1893 - accuracy: 0.9711 - val_loss: 0.1873 - val_accuracy: 0.9600\n",
            "Epoch 298/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.1748 - accuracy: 0.9778 - val_loss: 0.1892 - val_accuracy: 0.9600\n",
            "Epoch 299/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.1829 - accuracy: 0.9678 - val_loss: 0.1987 - val_accuracy: 0.9600\n",
            "Epoch 300/10000\n",
            "900/900 [==============================] - 0s 48us/step - loss: 0.1812 - accuracy: 0.9722 - val_loss: 0.1830 - val_accuracy: 0.9600\n",
            "Epoch 301/10000\n",
            "900/900 [==============================] - 0s 64us/step - loss: 0.1715 - accuracy: 0.9789 - val_loss: 0.1934 - val_accuracy: 0.9600\n",
            "Epoch 302/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.1813 - accuracy: 0.9733 - val_loss: 0.1879 - val_accuracy: 0.9600\n",
            "Epoch 303/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.1824 - accuracy: 0.9667 - val_loss: 0.2769 - val_accuracy: 0.8500\n",
            "Epoch 304/10000\n",
            "900/900 [==============================] - 0s 55us/step - loss: 0.1772 - accuracy: 0.9733 - val_loss: 0.1787 - val_accuracy: 0.9600\n",
            "Epoch 305/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.1897 - accuracy: 0.9589 - val_loss: 0.1781 - val_accuracy: 0.9700\n",
            "Epoch 306/10000\n",
            "900/900 [==============================] - 0s 47us/step - loss: 0.1809 - accuracy: 0.9722 - val_loss: 0.1804 - val_accuracy: 0.9600\n",
            "Epoch 307/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.1790 - accuracy: 0.9711 - val_loss: 0.1826 - val_accuracy: 0.9600\n",
            "Epoch 308/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.1741 - accuracy: 0.9689 - val_loss: 0.2066 - val_accuracy: 0.9400\n",
            "Epoch 309/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.1645 - accuracy: 0.9756 - val_loss: 0.1876 - val_accuracy: 0.9600\n",
            "Epoch 310/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.1666 - accuracy: 0.9822 - val_loss: 0.1642 - val_accuracy: 0.9800\n",
            "Epoch 311/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.1840 - accuracy: 0.9633 - val_loss: 0.2035 - val_accuracy: 0.9500\n",
            "Epoch 312/10000\n",
            "900/900 [==============================] - 0s 67us/step - loss: 0.1693 - accuracy: 0.9778 - val_loss: 0.1807 - val_accuracy: 0.9600\n",
            "Epoch 313/10000\n",
            "900/900 [==============================] - 0s 55us/step - loss: 0.1745 - accuracy: 0.9711 - val_loss: 0.1797 - val_accuracy: 0.9600\n",
            "Epoch 314/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.1765 - accuracy: 0.9689 - val_loss: 0.1804 - val_accuracy: 0.9700\n",
            "Epoch 315/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.1775 - accuracy: 0.9711 - val_loss: 0.1599 - val_accuracy: 0.9700\n",
            "Epoch 316/10000\n",
            "900/900 [==============================] - 0s 54us/step - loss: 0.1753 - accuracy: 0.9767 - val_loss: 0.1726 - val_accuracy: 0.9600\n",
            "Epoch 317/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.1604 - accuracy: 0.9789 - val_loss: 0.1849 - val_accuracy: 0.9600\n",
            "Epoch 318/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.1650 - accuracy: 0.9744 - val_loss: 0.1504 - val_accuracy: 0.9700\n",
            "Epoch 319/10000\n",
            "900/900 [==============================] - 0s 62us/step - loss: 0.1649 - accuracy: 0.9756 - val_loss: 0.1610 - val_accuracy: 0.9700\n",
            "Epoch 320/10000\n",
            "900/900 [==============================] - 0s 55us/step - loss: 0.1647 - accuracy: 0.9800 - val_loss: 0.1652 - val_accuracy: 0.9600\n",
            "Epoch 321/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.1732 - accuracy: 0.9644 - val_loss: 0.1654 - val_accuracy: 0.9700\n",
            "Epoch 322/10000\n",
            "900/900 [==============================] - 0s 48us/step - loss: 0.1652 - accuracy: 0.9722 - val_loss: 0.1549 - val_accuracy: 0.9700\n",
            "Epoch 323/10000\n",
            "900/900 [==============================] - 0s 62us/step - loss: 0.1688 - accuracy: 0.9778 - val_loss: 0.1598 - val_accuracy: 0.9600\n",
            "Epoch 324/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.1581 - accuracy: 0.9778 - val_loss: 0.1444 - val_accuracy: 0.9800\n",
            "Epoch 325/10000\n",
            "900/900 [==============================] - 0s 48us/step - loss: 0.1513 - accuracy: 0.9811 - val_loss: 0.1436 - val_accuracy: 0.9700\n",
            "Epoch 326/10000\n",
            "900/900 [==============================] - 0s 54us/step - loss: 0.1549 - accuracy: 0.9844 - val_loss: 0.1640 - val_accuracy: 0.9600\n",
            "Epoch 327/10000\n",
            "900/900 [==============================] - 0s 55us/step - loss: 0.1525 - accuracy: 0.9778 - val_loss: 0.2376 - val_accuracy: 0.9200\n",
            "Epoch 328/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.1607 - accuracy: 0.9633 - val_loss: 0.1441 - val_accuracy: 0.9700\n",
            "Epoch 329/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.1503 - accuracy: 0.9778 - val_loss: 0.2025 - val_accuracy: 0.9600\n",
            "Epoch 330/10000\n",
            "900/900 [==============================] - 0s 48us/step - loss: 0.1575 - accuracy: 0.9756 - val_loss: 0.2229 - val_accuracy: 0.9400\n",
            "Epoch 331/10000\n",
            "900/900 [==============================] - 0s 54us/step - loss: 0.1576 - accuracy: 0.9722 - val_loss: 0.1850 - val_accuracy: 0.9600\n",
            "Epoch 332/10000\n",
            "900/900 [==============================] - 0s 48us/step - loss: 0.1505 - accuracy: 0.9800 - val_loss: 0.1875 - val_accuracy: 0.9500\n",
            "Epoch 333/10000\n",
            "900/900 [==============================] - 0s 54us/step - loss: 0.1516 - accuracy: 0.9778 - val_loss: 0.1646 - val_accuracy: 0.9600\n",
            "Epoch 334/10000\n",
            "900/900 [==============================] - 0s 48us/step - loss: 0.1496 - accuracy: 0.9711 - val_loss: 0.1546 - val_accuracy: 0.9600\n",
            "Epoch 335/10000\n",
            "900/900 [==============================] - 0s 58us/step - loss: 0.1592 - accuracy: 0.9778 - val_loss: 0.1451 - val_accuracy: 0.9600\n",
            "Epoch 336/10000\n",
            "900/900 [==============================] - 0s 54us/step - loss: 0.1502 - accuracy: 0.9744 - val_loss: 0.1421 - val_accuracy: 0.9600\n",
            "Epoch 337/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.1494 - accuracy: 0.9800 - val_loss: 0.1434 - val_accuracy: 0.9600\n",
            "Epoch 338/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.1379 - accuracy: 0.9844 - val_loss: 0.1817 - val_accuracy: 0.9500\n",
            "Epoch 339/10000\n",
            "900/900 [==============================] - 0s 56us/step - loss: 0.1541 - accuracy: 0.9689 - val_loss: 0.1489 - val_accuracy: 0.9600\n",
            "Epoch 340/10000\n",
            "900/900 [==============================] - 0s 47us/step - loss: 0.1343 - accuracy: 0.9811 - val_loss: 0.1928 - val_accuracy: 0.9300\n",
            "Epoch 341/10000\n",
            "900/900 [==============================] - 0s 48us/step - loss: 0.1570 - accuracy: 0.9689 - val_loss: 0.1428 - val_accuracy: 0.9600\n",
            "Epoch 342/10000\n",
            "900/900 [==============================] - 0s 46us/step - loss: 0.1427 - accuracy: 0.9756 - val_loss: 0.1534 - val_accuracy: 0.9600\n",
            "Epoch 343/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.1482 - accuracy: 0.9722 - val_loss: 0.1452 - val_accuracy: 0.9600\n",
            "Epoch 344/10000\n",
            "900/900 [==============================] - 0s 58us/step - loss: 0.1434 - accuracy: 0.9767 - val_loss: 0.1473 - val_accuracy: 0.9600\n",
            "Epoch 345/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.1401 - accuracy: 0.9767 - val_loss: 0.1403 - val_accuracy: 0.9600\n",
            "Epoch 346/10000\n",
            "900/900 [==============================] - 0s 58us/step - loss: 0.1427 - accuracy: 0.9833 - val_loss: 0.1625 - val_accuracy: 0.9700\n",
            "Epoch 347/10000\n",
            "900/900 [==============================] - 0s 55us/step - loss: 0.1410 - accuracy: 0.9744 - val_loss: 0.1633 - val_accuracy: 0.9500\n",
            "Epoch 348/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.1406 - accuracy: 0.9789 - val_loss: 0.1913 - val_accuracy: 0.9500\n",
            "Epoch 349/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.1462 - accuracy: 0.9744 - val_loss: 0.1389 - val_accuracy: 0.9700\n",
            "Epoch 350/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.1415 - accuracy: 0.9756 - val_loss: 0.1628 - val_accuracy: 0.9500\n",
            "Epoch 351/10000\n",
            "900/900 [==============================] - 0s 55us/step - loss: 0.1393 - accuracy: 0.9733 - val_loss: 0.1509 - val_accuracy: 0.9600\n",
            "Epoch 352/10000\n",
            "900/900 [==============================] - 0s 47us/step - loss: 0.1361 - accuracy: 0.9767 - val_loss: 0.1362 - val_accuracy: 0.9600\n",
            "Epoch 353/10000\n",
            "900/900 [==============================] - 0s 55us/step - loss: 0.1284 - accuracy: 0.9811 - val_loss: 0.1345 - val_accuracy: 0.9800\n",
            "Epoch 354/10000\n",
            "900/900 [==============================] - 0s 57us/step - loss: 0.1488 - accuracy: 0.9689 - val_loss: 0.1329 - val_accuracy: 0.9600\n",
            "Epoch 355/10000\n",
            "900/900 [==============================] - 0s 55us/step - loss: 0.1278 - accuracy: 0.9844 - val_loss: 0.1441 - val_accuracy: 0.9600\n",
            "Epoch 356/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.1332 - accuracy: 0.9744 - val_loss: 0.1340 - val_accuracy: 0.9600\n",
            "Epoch 357/10000\n",
            "900/900 [==============================] - 0s 48us/step - loss: 0.1266 - accuracy: 0.9822 - val_loss: 0.1189 - val_accuracy: 0.9800\n",
            "Epoch 358/10000\n",
            "900/900 [==============================] - 0s 47us/step - loss: 0.1280 - accuracy: 0.9822 - val_loss: 0.1505 - val_accuracy: 0.9600\n",
            "Epoch 359/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.1285 - accuracy: 0.9767 - val_loss: 0.1474 - val_accuracy: 0.9600\n",
            "Epoch 360/10000\n",
            "900/900 [==============================] - 0s 54us/step - loss: 0.1212 - accuracy: 0.9822 - val_loss: 0.1253 - val_accuracy: 0.9600\n",
            "Epoch 361/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.1311 - accuracy: 0.9800 - val_loss: 0.1436 - val_accuracy: 0.9600\n",
            "Epoch 362/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.1271 - accuracy: 0.9778 - val_loss: 0.1774 - val_accuracy: 0.9400\n",
            "Epoch 363/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.1445 - accuracy: 0.9678 - val_loss: 0.1249 - val_accuracy: 0.9600\n",
            "Epoch 364/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.1344 - accuracy: 0.9756 - val_loss: 0.1533 - val_accuracy: 0.9600\n",
            "Epoch 365/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.1349 - accuracy: 0.9733 - val_loss: 0.1964 - val_accuracy: 0.9500\n",
            "Epoch 366/10000\n",
            "900/900 [==============================] - 0s 48us/step - loss: 0.1334 - accuracy: 0.9767 - val_loss: 0.1781 - val_accuracy: 0.9400\n",
            "Epoch 367/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.1300 - accuracy: 0.9744 - val_loss: 0.1265 - val_accuracy: 0.9800\n",
            "Epoch 368/10000\n",
            "900/900 [==============================] - 0s 48us/step - loss: 0.1150 - accuracy: 0.9878 - val_loss: 0.1416 - val_accuracy: 0.9600\n",
            "Epoch 369/10000\n",
            "900/900 [==============================] - 0s 56us/step - loss: 0.1233 - accuracy: 0.9767 - val_loss: 0.1461 - val_accuracy: 0.9600\n",
            "Epoch 370/10000\n",
            "900/900 [==============================] - 0s 56us/step - loss: 0.1325 - accuracy: 0.9778 - val_loss: 0.1305 - val_accuracy: 0.9600\n",
            "Epoch 371/10000\n",
            "900/900 [==============================] - 0s 59us/step - loss: 0.1224 - accuracy: 0.9778 - val_loss: 0.1686 - val_accuracy: 0.9600\n",
            "Epoch 372/10000\n",
            "900/900 [==============================] - 0s 56us/step - loss: 0.1279 - accuracy: 0.9822 - val_loss: 0.1187 - val_accuracy: 0.9700\n",
            "Epoch 373/10000\n",
            "900/900 [==============================] - 0s 60us/step - loss: 0.1244 - accuracy: 0.9800 - val_loss: 0.1064 - val_accuracy: 0.9800\n",
            "Epoch 374/10000\n",
            "900/900 [==============================] - 0s 57us/step - loss: 0.1256 - accuracy: 0.9700 - val_loss: 0.1271 - val_accuracy: 0.9600\n",
            "Epoch 375/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.1186 - accuracy: 0.9822 - val_loss: 0.1209 - val_accuracy: 0.9700\n",
            "Epoch 376/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.1141 - accuracy: 0.9833 - val_loss: 0.1514 - val_accuracy: 0.9600\n",
            "Epoch 377/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.1170 - accuracy: 0.9856 - val_loss: 0.1446 - val_accuracy: 0.9600\n",
            "Epoch 378/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.1136 - accuracy: 0.9778 - val_loss: 0.1068 - val_accuracy: 0.9800\n",
            "Epoch 379/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.1204 - accuracy: 0.9833 - val_loss: 0.1156 - val_accuracy: 0.9700\n",
            "Epoch 380/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.1206 - accuracy: 0.9811 - val_loss: 0.1082 - val_accuracy: 0.9800\n",
            "Epoch 381/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.1184 - accuracy: 0.9833 - val_loss: 0.1208 - val_accuracy: 0.9700\n",
            "Epoch 382/10000\n",
            "900/900 [==============================] - 0s 56us/step - loss: 0.1186 - accuracy: 0.9811 - val_loss: 0.1141 - val_accuracy: 0.9700\n",
            "Epoch 383/10000\n",
            "900/900 [==============================] - 0s 54us/step - loss: 0.1209 - accuracy: 0.9756 - val_loss: 0.0976 - val_accuracy: 0.9900\n",
            "Epoch 384/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.1182 - accuracy: 0.9822 - val_loss: 0.1137 - val_accuracy: 0.9700\n",
            "Epoch 385/10000\n",
            "900/900 [==============================] - 0s 48us/step - loss: 0.1293 - accuracy: 0.9700 - val_loss: 0.1075 - val_accuracy: 0.9700\n",
            "Epoch 386/10000\n",
            "900/900 [==============================] - 0s 47us/step - loss: 0.1222 - accuracy: 0.9811 - val_loss: 0.1290 - val_accuracy: 0.9700\n",
            "Epoch 387/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.1078 - accuracy: 0.9844 - val_loss: 0.1119 - val_accuracy: 0.9700\n",
            "Epoch 388/10000\n",
            "900/900 [==============================] - 0s 48us/step - loss: 0.1177 - accuracy: 0.9800 - val_loss: 0.1076 - val_accuracy: 0.9700\n",
            "Epoch 389/10000\n",
            "900/900 [==============================] - 0s 61us/step - loss: 0.1037 - accuracy: 0.9867 - val_loss: 0.1391 - val_accuracy: 0.9500\n",
            "Epoch 390/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.1251 - accuracy: 0.9700 - val_loss: 0.1189 - val_accuracy: 0.9600\n",
            "Epoch 391/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.1000 - accuracy: 0.9844 - val_loss: 0.1057 - val_accuracy: 0.9700\n",
            "Epoch 392/10000\n",
            "900/900 [==============================] - 0s 57us/step - loss: 0.1059 - accuracy: 0.9833 - val_loss: 0.1110 - val_accuracy: 0.9700\n",
            "Epoch 393/10000\n",
            "900/900 [==============================] - 0s 54us/step - loss: 0.1077 - accuracy: 0.9867 - val_loss: 0.1135 - val_accuracy: 0.9700\n",
            "Epoch 394/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.1288 - accuracy: 0.9722 - val_loss: 0.1216 - val_accuracy: 0.9700\n",
            "Epoch 395/10000\n",
            "900/900 [==============================] - 0s 57us/step - loss: 0.1060 - accuracy: 0.9856 - val_loss: 0.1347 - val_accuracy: 0.9600\n",
            "Epoch 396/10000\n",
            "900/900 [==============================] - 0s 48us/step - loss: 0.1160 - accuracy: 0.9767 - val_loss: 0.0979 - val_accuracy: 0.9800\n",
            "Epoch 397/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.1095 - accuracy: 0.9800 - val_loss: 0.1011 - val_accuracy: 0.9800\n",
            "Epoch 398/10000\n",
            "900/900 [==============================] - 0s 48us/step - loss: 0.1262 - accuracy: 0.9756 - val_loss: 0.1282 - val_accuracy: 0.9600\n",
            "Epoch 399/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.1149 - accuracy: 0.9833 - val_loss: 0.1006 - val_accuracy: 0.9800\n",
            "Epoch 400/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.1044 - accuracy: 0.9844 - val_loss: 0.1187 - val_accuracy: 0.9600\n",
            "Epoch 401/10000\n",
            "900/900 [==============================] - 0s 48us/step - loss: 0.1160 - accuracy: 0.9811 - val_loss: 0.1047 - val_accuracy: 0.9700\n",
            "Epoch 402/10000\n",
            "900/900 [==============================] - 0s 56us/step - loss: 0.0980 - accuracy: 0.9856 - val_loss: 0.1027 - val_accuracy: 0.9700\n",
            "Epoch 403/10000\n",
            "900/900 [==============================] - 0s 58us/step - loss: 0.1023 - accuracy: 0.9822 - val_loss: 0.0901 - val_accuracy: 0.9800\n",
            "Epoch 404/10000\n",
            "900/900 [==============================] - 0s 56us/step - loss: 0.0989 - accuracy: 0.9844 - val_loss: 0.1066 - val_accuracy: 0.9600\n",
            "Epoch 405/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.1082 - accuracy: 0.9744 - val_loss: 0.1203 - val_accuracy: 0.9600\n",
            "Epoch 406/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.1036 - accuracy: 0.9778 - val_loss: 0.0901 - val_accuracy: 0.9800\n",
            "Epoch 407/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.0960 - accuracy: 0.9878 - val_loss: 0.1004 - val_accuracy: 0.9700\n",
            "Epoch 408/10000\n",
            "900/900 [==============================] - 0s 61us/step - loss: 0.1022 - accuracy: 0.9800 - val_loss: 0.0887 - val_accuracy: 0.9800\n",
            "Epoch 409/10000\n",
            "900/900 [==============================] - 0s 58us/step - loss: 0.1060 - accuracy: 0.9822 - val_loss: 0.1311 - val_accuracy: 0.9600\n",
            "Epoch 410/10000\n",
            "900/900 [==============================] - 0s 47us/step - loss: 0.1029 - accuracy: 0.9778 - val_loss: 0.1406 - val_accuracy: 0.9600\n",
            "Epoch 411/10000\n",
            "900/900 [==============================] - 0s 57us/step - loss: 0.1048 - accuracy: 0.9811 - val_loss: 0.1086 - val_accuracy: 0.9700\n",
            "Epoch 412/10000\n",
            "900/900 [==============================] - 0s 54us/step - loss: 0.1007 - accuracy: 0.9856 - val_loss: 0.0872 - val_accuracy: 0.9800\n",
            "Epoch 413/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.0950 - accuracy: 0.9867 - val_loss: 0.1082 - val_accuracy: 0.9700\n",
            "Epoch 414/10000\n",
            "900/900 [==============================] - 0s 60us/step - loss: 0.0877 - accuracy: 0.9878 - val_loss: 0.1097 - val_accuracy: 0.9800\n",
            "Epoch 415/10000\n",
            "900/900 [==============================] - 0s 55us/step - loss: 0.1069 - accuracy: 0.9778 - val_loss: 0.0779 - val_accuracy: 0.9900\n",
            "Epoch 416/10000\n",
            "900/900 [==============================] - 0s 54us/step - loss: 0.0897 - accuracy: 0.9922 - val_loss: 0.0992 - val_accuracy: 0.9700\n",
            "Epoch 417/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.0947 - accuracy: 0.9900 - val_loss: 0.0886 - val_accuracy: 0.9800\n",
            "Epoch 418/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.0884 - accuracy: 0.9822 - val_loss: 0.1089 - val_accuracy: 0.9800\n",
            "Epoch 419/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.1044 - accuracy: 0.9778 - val_loss: 0.0880 - val_accuracy: 0.9800\n",
            "Epoch 420/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.0929 - accuracy: 0.9867 - val_loss: 0.0775 - val_accuracy: 0.9900\n",
            "Epoch 421/10000\n",
            "900/900 [==============================] - 0s 59us/step - loss: 0.0960 - accuracy: 0.9822 - val_loss: 0.0790 - val_accuracy: 0.9800\n",
            "Epoch 422/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.0985 - accuracy: 0.9822 - val_loss: 0.0929 - val_accuracy: 0.9700\n",
            "Epoch 423/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.0884 - accuracy: 0.9911 - val_loss: 0.0812 - val_accuracy: 0.9800\n",
            "Epoch 424/10000\n",
            "900/900 [==============================] - 0s 48us/step - loss: 0.0949 - accuracy: 0.9856 - val_loss: 0.0804 - val_accuracy: 0.9800\n",
            "Epoch 425/10000\n",
            "900/900 [==============================] - 0s 48us/step - loss: 0.1029 - accuracy: 0.9822 - val_loss: 0.1021 - val_accuracy: 0.9600\n",
            "Epoch 426/10000\n",
            "900/900 [==============================] - 0s 56us/step - loss: 0.0906 - accuracy: 0.9889 - val_loss: 0.0915 - val_accuracy: 0.9700\n",
            "Epoch 427/10000\n",
            "900/900 [==============================] - 0s 48us/step - loss: 0.1006 - accuracy: 0.9844 - val_loss: 0.0881 - val_accuracy: 0.9800\n",
            "Epoch 428/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.0941 - accuracy: 0.9867 - val_loss: 0.1005 - val_accuracy: 0.9700\n",
            "Epoch 429/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.0826 - accuracy: 0.9900 - val_loss: 0.0764 - val_accuracy: 0.9800\n",
            "Epoch 430/10000\n",
            "900/900 [==============================] - 0s 65us/step - loss: 0.0849 - accuracy: 0.9911 - val_loss: 0.0851 - val_accuracy: 0.9800\n",
            "Epoch 431/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.1020 - accuracy: 0.9756 - val_loss: 0.1017 - val_accuracy: 0.9700\n",
            "Epoch 432/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.0909 - accuracy: 0.9856 - val_loss: 0.0759 - val_accuracy: 0.9900\n",
            "Epoch 433/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.0997 - accuracy: 0.9844 - val_loss: 0.0965 - val_accuracy: 0.9700\n",
            "Epoch 434/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.0844 - accuracy: 0.9911 - val_loss: 0.0798 - val_accuracy: 0.9800\n",
            "Epoch 435/10000\n",
            "900/900 [==============================] - 0s 47us/step - loss: 0.0993 - accuracy: 0.9767 - val_loss: 0.0874 - val_accuracy: 0.9700\n",
            "Epoch 436/10000\n",
            "900/900 [==============================] - 0s 62us/step - loss: 0.0989 - accuracy: 0.9789 - val_loss: 0.1138 - val_accuracy: 0.9600\n",
            "Epoch 437/10000\n",
            "900/900 [==============================] - 0s 54us/step - loss: 0.0899 - accuracy: 0.9822 - val_loss: 0.0978 - val_accuracy: 0.9700\n",
            "Epoch 438/10000\n",
            "900/900 [==============================] - 0s 56us/step - loss: 0.0879 - accuracy: 0.9844 - val_loss: 0.0798 - val_accuracy: 0.9800\n",
            "Epoch 439/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.0920 - accuracy: 0.9867 - val_loss: 0.0872 - val_accuracy: 0.9700\n",
            "Epoch 440/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.0943 - accuracy: 0.9789 - val_loss: 0.0855 - val_accuracy: 0.9800\n",
            "Epoch 441/10000\n",
            "900/900 [==============================] - 0s 54us/step - loss: 0.0829 - accuracy: 0.9900 - val_loss: 0.0779 - val_accuracy: 0.9800\n",
            "Epoch 442/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.0959 - accuracy: 0.9778 - val_loss: 0.0925 - val_accuracy: 0.9600\n",
            "Epoch 443/10000\n",
            "900/900 [==============================] - 0s 57us/step - loss: 0.0948 - accuracy: 0.9800 - val_loss: 0.0839 - val_accuracy: 0.9700\n",
            "Epoch 444/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.0999 - accuracy: 0.9756 - val_loss: 0.0710 - val_accuracy: 0.9900\n",
            "Epoch 445/10000\n",
            "900/900 [==============================] - 0s 58us/step - loss: 0.0779 - accuracy: 0.9889 - val_loss: 0.0776 - val_accuracy: 0.9800\n",
            "Epoch 446/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.0972 - accuracy: 0.9778 - val_loss: 0.0750 - val_accuracy: 0.9800\n",
            "Epoch 447/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.0823 - accuracy: 0.9856 - val_loss: 0.1001 - val_accuracy: 0.9700\n",
            "Epoch 448/10000\n",
            "900/900 [==============================] - 0s 58us/step - loss: 0.0873 - accuracy: 0.9856 - val_loss: 0.0768 - val_accuracy: 0.9800\n",
            "Epoch 449/10000\n",
            "900/900 [==============================] - 0s 59us/step - loss: 0.0793 - accuracy: 0.9889 - val_loss: 0.1067 - val_accuracy: 0.9700\n",
            "Epoch 450/10000\n",
            "900/900 [==============================] - 0s 59us/step - loss: 0.0940 - accuracy: 0.9811 - val_loss: 0.0825 - val_accuracy: 0.9800\n",
            "Epoch 451/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.0801 - accuracy: 0.9900 - val_loss: 0.0685 - val_accuracy: 0.9800\n",
            "Epoch 452/10000\n",
            "900/900 [==============================] - 0s 97us/step - loss: 0.0933 - accuracy: 0.9789 - val_loss: 0.0931 - val_accuracy: 0.9700\n",
            "Epoch 453/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.0989 - accuracy: 0.9756 - val_loss: 0.0880 - val_accuracy: 0.9800\n",
            "Epoch 454/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.0884 - accuracy: 0.9800 - val_loss: 0.0848 - val_accuracy: 0.9700\n",
            "Epoch 455/10000\n",
            "900/900 [==============================] - 0s 54us/step - loss: 0.0796 - accuracy: 0.9900 - val_loss: 0.0703 - val_accuracy: 0.9800\n",
            "Epoch 456/10000\n",
            "900/900 [==============================] - 0s 54us/step - loss: 0.0788 - accuracy: 0.9911 - val_loss: 0.0937 - val_accuracy: 0.9800\n",
            "Epoch 457/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.0828 - accuracy: 0.9856 - val_loss: 0.1030 - val_accuracy: 0.9700\n",
            "Epoch 458/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.0925 - accuracy: 0.9811 - val_loss: 0.0714 - val_accuracy: 0.9800\n",
            "Epoch 459/10000\n",
            "900/900 [==============================] - 0s 56us/step - loss: 0.0863 - accuracy: 0.9833 - val_loss: 0.0955 - val_accuracy: 0.9600\n",
            "Epoch 460/10000\n",
            "900/900 [==============================] - 0s 54us/step - loss: 0.0806 - accuracy: 0.9856 - val_loss: 0.0921 - val_accuracy: 0.9700\n",
            "Epoch 461/10000\n",
            "900/900 [==============================] - 0s 48us/step - loss: 0.0749 - accuracy: 0.9900 - val_loss: 0.0651 - val_accuracy: 0.9900\n",
            "Epoch 462/10000\n",
            "900/900 [==============================] - 0s 48us/step - loss: 0.0937 - accuracy: 0.9767 - val_loss: 0.0800 - val_accuracy: 0.9800\n",
            "Epoch 463/10000\n",
            "900/900 [==============================] - 0s 56us/step - loss: 0.0917 - accuracy: 0.9789 - val_loss: 0.0657 - val_accuracy: 0.9800\n",
            "Epoch 464/10000\n",
            "900/900 [==============================] - 0s 59us/step - loss: 0.0817 - accuracy: 0.9856 - val_loss: 0.0916 - val_accuracy: 0.9700\n",
            "Epoch 465/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.0878 - accuracy: 0.9822 - val_loss: 0.0681 - val_accuracy: 0.9800\n",
            "Epoch 466/10000\n",
            "900/900 [==============================] - 0s 55us/step - loss: 0.0775 - accuracy: 0.9878 - val_loss: 0.0887 - val_accuracy: 0.9800\n",
            "Epoch 467/10000\n",
            "900/900 [==============================] - 0s 60us/step - loss: 0.0763 - accuracy: 0.9833 - val_loss: 0.0857 - val_accuracy: 0.9800\n",
            "Epoch 468/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.0836 - accuracy: 0.9844 - val_loss: 0.0715 - val_accuracy: 0.9800\n",
            "Epoch 469/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.0743 - accuracy: 0.9856 - val_loss: 0.0936 - val_accuracy: 0.9600\n",
            "Epoch 470/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.0831 - accuracy: 0.9811 - val_loss: 0.0726 - val_accuracy: 0.9800\n",
            "Epoch 471/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.0762 - accuracy: 0.9856 - val_loss: 0.0735 - val_accuracy: 0.9700\n",
            "Epoch 472/10000\n",
            "900/900 [==============================] - 0s 47us/step - loss: 0.0767 - accuracy: 0.9900 - val_loss: 0.0844 - val_accuracy: 0.9700\n",
            "Epoch 473/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.0772 - accuracy: 0.9900 - val_loss: 0.0807 - val_accuracy: 0.9700\n",
            "Epoch 474/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.0835 - accuracy: 0.9856 - val_loss: 0.1075 - val_accuracy: 0.9600\n",
            "Epoch 475/10000\n",
            "900/900 [==============================] - 0s 47us/step - loss: 0.0788 - accuracy: 0.9889 - val_loss: 0.0825 - val_accuracy: 0.9800\n",
            "Epoch 476/10000\n",
            "900/900 [==============================] - 0s 55us/step - loss: 0.0928 - accuracy: 0.9811 - val_loss: 0.1145 - val_accuracy: 0.9600\n",
            "Epoch 477/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.0739 - accuracy: 0.9900 - val_loss: 0.1407 - val_accuracy: 0.9600\n",
            "Epoch 478/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.0868 - accuracy: 0.9811 - val_loss: 0.0765 - val_accuracy: 0.9700\n",
            "Epoch 479/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.0670 - accuracy: 0.9878 - val_loss: 0.0594 - val_accuracy: 0.9800\n",
            "Epoch 480/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.0807 - accuracy: 0.9867 - val_loss: 0.1138 - val_accuracy: 0.9600\n",
            "Epoch 481/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.0895 - accuracy: 0.9800 - val_loss: 0.0719 - val_accuracy: 0.9800\n",
            "Epoch 482/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.0770 - accuracy: 0.9878 - val_loss: 0.0745 - val_accuracy: 0.9700\n",
            "Epoch 483/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.0730 - accuracy: 0.9900 - val_loss: 0.0787 - val_accuracy: 0.9700\n",
            "Epoch 484/10000\n",
            "900/900 [==============================] - 0s 54us/step - loss: 0.0819 - accuracy: 0.9811 - val_loss: 0.0762 - val_accuracy: 0.9800\n",
            "Epoch 485/10000\n",
            "900/900 [==============================] - 0s 59us/step - loss: 0.0780 - accuracy: 0.9900 - val_loss: 0.1010 - val_accuracy: 0.9600\n",
            "Epoch 486/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.0740 - accuracy: 0.9833 - val_loss: 0.1142 - val_accuracy: 0.9600\n",
            "Epoch 487/10000\n",
            "900/900 [==============================] - 0s 47us/step - loss: 0.0811 - accuracy: 0.9822 - val_loss: 0.1133 - val_accuracy: 0.9600\n",
            "Epoch 488/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.0730 - accuracy: 0.9833 - val_loss: 0.0617 - val_accuracy: 0.9900\n",
            "Epoch 489/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.0801 - accuracy: 0.9800 - val_loss: 0.0844 - val_accuracy: 0.9700\n",
            "Epoch 490/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.0791 - accuracy: 0.9811 - val_loss: 0.0819 - val_accuracy: 0.9700\n",
            "Epoch 491/10000\n",
            "900/900 [==============================] - 0s 46us/step - loss: 0.0817 - accuracy: 0.9878 - val_loss: 0.0644 - val_accuracy: 1.0000\n",
            "Epoch 492/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.0754 - accuracy: 0.9856 - val_loss: 0.1141 - val_accuracy: 0.9600\n",
            "Epoch 493/10000\n",
            "900/900 [==============================] - 0s 67us/step - loss: 0.0716 - accuracy: 0.9889 - val_loss: 0.1300 - val_accuracy: 0.9600\n",
            "Epoch 494/10000\n",
            "900/900 [==============================] - 0s 55us/step - loss: 0.0858 - accuracy: 0.9744 - val_loss: 0.0586 - val_accuracy: 0.9900\n",
            "Epoch 495/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.0746 - accuracy: 0.9911 - val_loss: 0.0577 - val_accuracy: 0.9800\n",
            "Epoch 496/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.0749 - accuracy: 0.9878 - val_loss: 0.0641 - val_accuracy: 0.9900\n",
            "Epoch 497/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.0758 - accuracy: 0.9867 - val_loss: 0.0695 - val_accuracy: 0.9700\n",
            "Epoch 498/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.0652 - accuracy: 0.9844 - val_loss: 0.0829 - val_accuracy: 0.9600\n",
            "Epoch 499/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.0681 - accuracy: 0.9900 - val_loss: 0.0969 - val_accuracy: 0.9600\n",
            "Epoch 500/10000\n",
            "900/900 [==============================] - 0s 59us/step - loss: 0.0716 - accuracy: 0.9933 - val_loss: 0.0885 - val_accuracy: 0.9700\n",
            "Epoch 501/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.0743 - accuracy: 0.9844 - val_loss: 0.0644 - val_accuracy: 0.9700\n",
            "Epoch 502/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.0659 - accuracy: 0.9867 - val_loss: 0.1019 - val_accuracy: 0.9600\n",
            "Epoch 503/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.0724 - accuracy: 0.9889 - val_loss: 0.0805 - val_accuracy: 0.9700\n",
            "Epoch 504/10000\n",
            "900/900 [==============================] - 0s 76us/step - loss: 0.0780 - accuracy: 0.9911 - val_loss: 0.0755 - val_accuracy: 0.9700\n",
            "Epoch 505/10000\n",
            "900/900 [==============================] - 0s 54us/step - loss: 0.0709 - accuracy: 0.9878 - val_loss: 0.0858 - val_accuracy: 0.9800\n",
            "Epoch 506/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.0602 - accuracy: 0.9933 - val_loss: 0.0646 - val_accuracy: 0.9800\n",
            "Epoch 507/10000\n",
            "900/900 [==============================] - 0s 56us/step - loss: 0.0664 - accuracy: 0.9911 - val_loss: 0.0909 - val_accuracy: 0.9700\n",
            "Epoch 508/10000\n",
            "900/900 [==============================] - 0s 48us/step - loss: 0.0675 - accuracy: 0.9922 - val_loss: 0.0598 - val_accuracy: 0.9800\n",
            "Epoch 509/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.0823 - accuracy: 0.9878 - val_loss: 0.0900 - val_accuracy: 0.9700\n",
            "Epoch 510/10000\n",
            "900/900 [==============================] - 0s 46us/step - loss: 0.0788 - accuracy: 0.9811 - val_loss: 0.0548 - val_accuracy: 0.9900\n",
            "Epoch 511/10000\n",
            "900/900 [==============================] - 0s 46us/step - loss: 0.0670 - accuracy: 0.9878 - val_loss: 0.0609 - val_accuracy: 0.9800\n",
            "Epoch 512/10000\n",
            "900/900 [==============================] - 0s 55us/step - loss: 0.0698 - accuracy: 0.9833 - val_loss: 0.0593 - val_accuracy: 0.9800\n",
            "Epoch 513/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.0654 - accuracy: 0.9900 - val_loss: 0.0916 - val_accuracy: 0.9700\n",
            "Epoch 514/10000\n",
            "900/900 [==============================] - 0s 46us/step - loss: 0.0598 - accuracy: 0.9922 - val_loss: 0.0809 - val_accuracy: 0.9800\n",
            "Epoch 515/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.0678 - accuracy: 0.9878 - val_loss: 0.0834 - val_accuracy: 0.9600\n",
            "Epoch 516/10000\n",
            "900/900 [==============================] - 0s 67us/step - loss: 0.0753 - accuracy: 0.9844 - val_loss: 0.0715 - val_accuracy: 0.9700\n",
            "Epoch 517/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.0627 - accuracy: 0.9878 - val_loss: 0.0688 - val_accuracy: 0.9700\n",
            "Epoch 518/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.0629 - accuracy: 0.9900 - val_loss: 0.0497 - val_accuracy: 0.9900\n",
            "Epoch 519/10000\n",
            "900/900 [==============================] - 0s 55us/step - loss: 0.0682 - accuracy: 0.9856 - val_loss: 0.0501 - val_accuracy: 0.9900\n",
            "Epoch 520/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.0624 - accuracy: 0.9900 - val_loss: 0.1050 - val_accuracy: 0.9600\n",
            "Epoch 521/10000\n",
            "900/900 [==============================] - 0s 47us/step - loss: 0.0760 - accuracy: 0.9856 - val_loss: 0.0828 - val_accuracy: 0.9700\n",
            "Epoch 522/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.0785 - accuracy: 0.9800 - val_loss: 0.0482 - val_accuracy: 0.9900\n",
            "Epoch 523/10000\n",
            "900/900 [==============================] - 0s 58us/step - loss: 0.0734 - accuracy: 0.9833 - val_loss: 0.0700 - val_accuracy: 0.9800\n",
            "Epoch 524/10000\n",
            "900/900 [==============================] - 0s 57us/step - loss: 0.0663 - accuracy: 0.9889 - val_loss: 0.0720 - val_accuracy: 0.9800\n",
            "Epoch 525/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.0783 - accuracy: 0.9811 - val_loss: 0.0805 - val_accuracy: 0.9600\n",
            "Epoch 526/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.0657 - accuracy: 0.9900 - val_loss: 0.0628 - val_accuracy: 0.9800\n",
            "Epoch 527/10000\n",
            "900/900 [==============================] - 0s 55us/step - loss: 0.0623 - accuracy: 0.9889 - val_loss: 0.0540 - val_accuracy: 0.9800\n",
            "Epoch 528/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.0747 - accuracy: 0.9789 - val_loss: 0.0716 - val_accuracy: 0.9700\n",
            "Epoch 529/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.0719 - accuracy: 0.9844 - val_loss: 0.0707 - val_accuracy: 0.9700\n",
            "Epoch 530/10000\n",
            "900/900 [==============================] - 0s 48us/step - loss: 0.0692 - accuracy: 0.9856 - val_loss: 0.0911 - val_accuracy: 0.9700\n",
            "Epoch 531/10000\n",
            "900/900 [==============================] - 0s 57us/step - loss: 0.0597 - accuracy: 0.9900 - val_loss: 0.0969 - val_accuracy: 0.9700\n",
            "Epoch 532/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.0730 - accuracy: 0.9822 - val_loss: 0.0682 - val_accuracy: 0.9800\n",
            "Epoch 533/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.0738 - accuracy: 0.9833 - val_loss: 0.0679 - val_accuracy: 0.9700\n",
            "Epoch 534/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.0729 - accuracy: 0.9911 - val_loss: 0.0974 - val_accuracy: 0.9600\n",
            "Epoch 535/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.0730 - accuracy: 0.9833 - val_loss: 0.0730 - val_accuracy: 0.9700\n",
            "Epoch 536/10000\n",
            "900/900 [==============================] - 0s 60us/step - loss: 0.0662 - accuracy: 0.9867 - val_loss: 0.0662 - val_accuracy: 0.9700\n",
            "Epoch 537/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.0739 - accuracy: 0.9811 - val_loss: 0.0517 - val_accuracy: 0.9800\n",
            "Epoch 538/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.0772 - accuracy: 0.9833 - val_loss: 0.0487 - val_accuracy: 0.9900\n",
            "Epoch 539/10000\n",
            "900/900 [==============================] - 0s 58us/step - loss: 0.0535 - accuracy: 0.9922 - val_loss: 0.0657 - val_accuracy: 0.9700\n",
            "Epoch 540/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.0608 - accuracy: 0.9867 - val_loss: 0.0576 - val_accuracy: 0.9800\n",
            "Epoch 541/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.0547 - accuracy: 0.9922 - val_loss: 0.0755 - val_accuracy: 0.9600\n",
            "Epoch 542/10000\n",
            "900/900 [==============================] - 0s 58us/step - loss: 0.0697 - accuracy: 0.9856 - val_loss: 0.0463 - val_accuracy: 0.9900\n",
            "Epoch 543/10000\n",
            "900/900 [==============================] - 0s 58us/step - loss: 0.0602 - accuracy: 0.9900 - val_loss: 0.0557 - val_accuracy: 0.9800\n",
            "Epoch 544/10000\n",
            "900/900 [==============================] - 0s 47us/step - loss: 0.0535 - accuracy: 0.9933 - val_loss: 0.0660 - val_accuracy: 0.9700\n",
            "Epoch 545/10000\n",
            "900/900 [==============================] - 0s 47us/step - loss: 0.0760 - accuracy: 0.9844 - val_loss: 0.0734 - val_accuracy: 0.9600\n",
            "Epoch 546/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.0689 - accuracy: 0.9822 - val_loss: 0.0538 - val_accuracy: 0.9900\n",
            "Epoch 547/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.0567 - accuracy: 0.9878 - val_loss: 0.0495 - val_accuracy: 0.9900\n",
            "Epoch 548/10000\n",
            "900/900 [==============================] - 0s 56us/step - loss: 0.0640 - accuracy: 0.9889 - val_loss: 0.0589 - val_accuracy: 0.9800\n",
            "Epoch 549/10000\n",
            "900/900 [==============================] - 0s 47us/step - loss: 0.0601 - accuracy: 0.9911 - val_loss: 0.0580 - val_accuracy: 0.9700\n",
            "Epoch 550/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.0610 - accuracy: 0.9911 - val_loss: 0.0843 - val_accuracy: 0.9600\n",
            "Epoch 551/10000\n",
            "900/900 [==============================] - 0s 65us/step - loss: 0.0604 - accuracy: 0.9856 - val_loss: 0.0867 - val_accuracy: 0.9600\n",
            "Epoch 552/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.0712 - accuracy: 0.9844 - val_loss: 0.0585 - val_accuracy: 0.9700\n",
            "Epoch 553/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.0483 - accuracy: 0.9922 - val_loss: 0.0468 - val_accuracy: 0.9900\n",
            "Epoch 554/10000\n",
            "900/900 [==============================] - 0s 48us/step - loss: 0.0597 - accuracy: 0.9911 - val_loss: 0.0730 - val_accuracy: 0.9700\n",
            "Epoch 555/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.0601 - accuracy: 0.9911 - val_loss: 0.0609 - val_accuracy: 0.9800\n",
            "Epoch 556/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.0590 - accuracy: 0.9900 - val_loss: 0.0429 - val_accuracy: 0.9900\n",
            "Epoch 557/10000\n",
            "900/900 [==============================] - 0s 57us/step - loss: 0.0600 - accuracy: 0.9911 - val_loss: 0.0602 - val_accuracy: 0.9700\n",
            "Epoch 558/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.0677 - accuracy: 0.9833 - val_loss: 0.0519 - val_accuracy: 0.9800\n",
            "Epoch 559/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.0705 - accuracy: 0.9856 - val_loss: 0.0695 - val_accuracy: 0.9700\n",
            "Epoch 560/10000\n",
            "900/900 [==============================] - 0s 54us/step - loss: 0.0649 - accuracy: 0.9889 - val_loss: 0.0664 - val_accuracy: 0.9700\n",
            "Epoch 561/10000\n",
            "900/900 [==============================] - 0s 56us/step - loss: 0.0506 - accuracy: 0.9922 - val_loss: 0.1423 - val_accuracy: 0.9400\n",
            "Epoch 562/10000\n",
            "900/900 [==============================] - 0s 54us/step - loss: 0.0765 - accuracy: 0.9778 - val_loss: 0.0482 - val_accuracy: 0.9900\n",
            "Epoch 563/10000\n",
            "900/900 [==============================] - 0s 55us/step - loss: 0.0620 - accuracy: 0.9889 - val_loss: 0.0478 - val_accuracy: 0.9900\n",
            "Epoch 564/10000\n",
            "900/900 [==============================] - 0s 54us/step - loss: 0.0491 - accuracy: 0.9944 - val_loss: 0.0771 - val_accuracy: 0.9700\n",
            "Epoch 565/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.0555 - accuracy: 0.9900 - val_loss: 0.1038 - val_accuracy: 0.9600\n",
            "Epoch 566/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.0595 - accuracy: 0.9822 - val_loss: 0.0504 - val_accuracy: 0.9800\n",
            "Epoch 567/10000\n",
            "900/900 [==============================] - 0s 58us/step - loss: 0.0691 - accuracy: 0.9856 - val_loss: 0.0767 - val_accuracy: 0.9600\n",
            "Epoch 568/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.0551 - accuracy: 0.9933 - val_loss: 0.0585 - val_accuracy: 0.9800\n",
            "Epoch 569/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.0619 - accuracy: 0.9889 - val_loss: 0.0619 - val_accuracy: 0.9800\n",
            "Epoch 570/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.0541 - accuracy: 0.9944 - val_loss: 0.0504 - val_accuracy: 0.9900\n",
            "Epoch 571/10000\n",
            "900/900 [==============================] - 0s 47us/step - loss: 0.0509 - accuracy: 0.9922 - val_loss: 0.0464 - val_accuracy: 0.9900\n",
            "Epoch 572/10000\n",
            "900/900 [==============================] - 0s 56us/step - loss: 0.0613 - accuracy: 0.9856 - val_loss: 0.0523 - val_accuracy: 0.9800\n",
            "Epoch 573/10000\n",
            "900/900 [==============================] - 0s 48us/step - loss: 0.0466 - accuracy: 0.9933 - val_loss: 0.0717 - val_accuracy: 0.9700\n",
            "Epoch 574/10000\n",
            "900/900 [==============================] - 0s 54us/step - loss: 0.0578 - accuracy: 0.9900 - val_loss: 0.0484 - val_accuracy: 0.9900\n",
            "Epoch 575/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.0614 - accuracy: 0.9889 - val_loss: 0.0724 - val_accuracy: 0.9700\n",
            "Epoch 576/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.0493 - accuracy: 0.9967 - val_loss: 0.0497 - val_accuracy: 0.9900\n",
            "Epoch 577/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.0582 - accuracy: 0.9867 - val_loss: 0.0430 - val_accuracy: 0.9900\n",
            "Epoch 578/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.0675 - accuracy: 0.9878 - val_loss: 0.0696 - val_accuracy: 0.9700\n",
            "Epoch 579/10000\n",
            "900/900 [==============================] - 0s 60us/step - loss: 0.0572 - accuracy: 0.9900 - val_loss: 0.0701 - val_accuracy: 0.9700\n",
            "Epoch 580/10000\n",
            "900/900 [==============================] - 0s 55us/step - loss: 0.0419 - accuracy: 0.9956 - val_loss: 0.0515 - val_accuracy: 0.9900\n",
            "Epoch 581/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.0502 - accuracy: 0.9922 - val_loss: 0.0901 - val_accuracy: 0.9600\n",
            "Epoch 582/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.0556 - accuracy: 0.9856 - val_loss: 0.0598 - val_accuracy: 0.9700\n",
            "Epoch 583/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.0507 - accuracy: 0.9944 - val_loss: 0.0635 - val_accuracy: 0.9700\n",
            "Epoch 584/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.0564 - accuracy: 0.9878 - val_loss: 0.0479 - val_accuracy: 0.9900\n",
            "Epoch 585/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.0603 - accuracy: 0.9856 - val_loss: 0.0671 - val_accuracy: 0.9700\n",
            "Epoch 586/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.0482 - accuracy: 0.9922 - val_loss: 0.0683 - val_accuracy: 0.9800\n",
            "Epoch 587/10000\n",
            "900/900 [==============================] - 0s 48us/step - loss: 0.0661 - accuracy: 0.9867 - val_loss: 0.0435 - val_accuracy: 0.9900\n",
            "Epoch 588/10000\n",
            "900/900 [==============================] - 0s 54us/step - loss: 0.0624 - accuracy: 0.9878 - val_loss: 0.0648 - val_accuracy: 0.9700\n",
            "Epoch 589/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.0632 - accuracy: 0.9844 - val_loss: 0.0426 - val_accuracy: 0.9900\n",
            "Epoch 590/10000\n",
            "900/900 [==============================] - 0s 56us/step - loss: 0.0520 - accuracy: 0.9889 - val_loss: 0.0418 - val_accuracy: 0.9900\n",
            "Epoch 591/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.0541 - accuracy: 0.9900 - val_loss: 0.0479 - val_accuracy: 0.9800\n",
            "Epoch 592/10000\n",
            "900/900 [==============================] - 0s 48us/step - loss: 0.0530 - accuracy: 0.9878 - val_loss: 0.0654 - val_accuracy: 0.9800\n",
            "Epoch 593/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.0527 - accuracy: 0.9889 - val_loss: 0.0631 - val_accuracy: 0.9700\n",
            "Epoch 594/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.0540 - accuracy: 0.9922 - val_loss: 0.0515 - val_accuracy: 0.9900\n",
            "Epoch 595/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.0477 - accuracy: 0.9922 - val_loss: 0.0545 - val_accuracy: 0.9800\n",
            "Epoch 596/10000\n",
            "900/900 [==============================] - 0s 47us/step - loss: 0.0605 - accuracy: 0.9844 - val_loss: 0.0763 - val_accuracy: 0.9700\n",
            "Epoch 597/10000\n",
            "900/900 [==============================] - 0s 58us/step - loss: 0.0598 - accuracy: 0.9867 - val_loss: 0.0579 - val_accuracy: 0.9800\n",
            "Epoch 598/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.0568 - accuracy: 0.9889 - val_loss: 0.0428 - val_accuracy: 0.9900\n",
            "Epoch 599/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.0570 - accuracy: 0.9900 - val_loss: 0.0457 - val_accuracy: 0.9900\n",
            "Epoch 600/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.0517 - accuracy: 0.9889 - val_loss: 0.0350 - val_accuracy: 1.0000\n",
            "Epoch 601/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.0448 - accuracy: 0.9911 - val_loss: 0.0421 - val_accuracy: 0.9900\n",
            "Epoch 602/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.0521 - accuracy: 0.9878 - val_loss: 0.0455 - val_accuracy: 0.9900\n",
            "Epoch 603/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.0519 - accuracy: 0.9889 - val_loss: 0.0396 - val_accuracy: 0.9900\n",
            "Epoch 604/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.0532 - accuracy: 0.9900 - val_loss: 0.0449 - val_accuracy: 0.9800\n",
            "Epoch 605/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.0494 - accuracy: 0.9922 - val_loss: 0.0389 - val_accuracy: 0.9900\n",
            "Epoch 606/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.0517 - accuracy: 0.9867 - val_loss: 0.0484 - val_accuracy: 0.9800\n",
            "Epoch 607/10000\n",
            "900/900 [==============================] - 0s 55us/step - loss: 0.0659 - accuracy: 0.9756 - val_loss: 0.0391 - val_accuracy: 0.9900\n",
            "Epoch 608/10000\n",
            "900/900 [==============================] - 0s 48us/step - loss: 0.0604 - accuracy: 0.9844 - val_loss: 0.0304 - val_accuracy: 1.0000\n",
            "Epoch 609/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.0478 - accuracy: 0.9911 - val_loss: 0.0340 - val_accuracy: 1.0000\n",
            "Epoch 610/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.0494 - accuracy: 0.9900 - val_loss: 0.0512 - val_accuracy: 0.9700\n",
            "Epoch 611/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.0480 - accuracy: 0.9900 - val_loss: 0.0595 - val_accuracy: 0.9700\n",
            "Epoch 612/10000\n",
            "900/900 [==============================] - 0s 48us/step - loss: 0.0459 - accuracy: 0.9944 - val_loss: 0.0594 - val_accuracy: 0.9800\n",
            "Epoch 613/10000\n",
            "900/900 [==============================] - 0s 55us/step - loss: 0.0526 - accuracy: 0.9911 - val_loss: 0.0427 - val_accuracy: 0.9900\n",
            "Epoch 614/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.0485 - accuracy: 0.9911 - val_loss: 0.0405 - val_accuracy: 0.9900\n",
            "Epoch 615/10000\n",
            "900/900 [==============================] - 0s 58us/step - loss: 0.0420 - accuracy: 0.9956 - val_loss: 0.0751 - val_accuracy: 0.9700\n",
            "Epoch 616/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.0626 - accuracy: 0.9856 - val_loss: 0.0356 - val_accuracy: 1.0000\n",
            "Epoch 617/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.0520 - accuracy: 0.9956 - val_loss: 0.0483 - val_accuracy: 0.9800\n",
            "Epoch 618/10000\n",
            "900/900 [==============================] - 0s 63us/step - loss: 0.0473 - accuracy: 0.9933 - val_loss: 0.0416 - val_accuracy: 0.9900\n",
            "Epoch 619/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.0411 - accuracy: 0.9978 - val_loss: 0.0489 - val_accuracy: 0.9800\n",
            "Epoch 620/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.0590 - accuracy: 0.9900 - val_loss: 0.0482 - val_accuracy: 0.9800\n",
            "Epoch 621/10000\n",
            "900/900 [==============================] - 0s 47us/step - loss: 0.0521 - accuracy: 0.9900 - val_loss: 0.0588 - val_accuracy: 0.9700\n",
            "Epoch 622/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.0422 - accuracy: 0.9944 - val_loss: 0.0397 - val_accuracy: 0.9900\n",
            "Epoch 623/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.0560 - accuracy: 0.9889 - val_loss: 0.0893 - val_accuracy: 0.9600\n",
            "Epoch 624/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.0624 - accuracy: 0.9822 - val_loss: 0.0545 - val_accuracy: 0.9700\n",
            "Epoch 625/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.0494 - accuracy: 0.9889 - val_loss: 0.0409 - val_accuracy: 0.9900\n",
            "Epoch 626/10000\n",
            "900/900 [==============================] - 0s 54us/step - loss: 0.0494 - accuracy: 0.9911 - val_loss: 0.0464 - val_accuracy: 0.9900\n",
            "Epoch 627/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.0419 - accuracy: 0.9944 - val_loss: 0.0527 - val_accuracy: 0.9700\n",
            "Epoch 628/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.0584 - accuracy: 0.9889 - val_loss: 0.0510 - val_accuracy: 0.9800\n",
            "Epoch 629/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.0395 - accuracy: 0.9956 - val_loss: 0.0478 - val_accuracy: 0.9800\n",
            "Epoch 630/10000\n",
            "900/900 [==============================] - 0s 59us/step - loss: 0.0460 - accuracy: 0.9911 - val_loss: 0.0403 - val_accuracy: 0.9900\n",
            "Epoch 631/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.0619 - accuracy: 0.9822 - val_loss: 0.0563 - val_accuracy: 0.9900\n",
            "Epoch 632/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.0505 - accuracy: 0.9922 - val_loss: 0.0724 - val_accuracy: 0.9600\n",
            "Epoch 633/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.0498 - accuracy: 0.9933 - val_loss: 0.0461 - val_accuracy: 0.9800\n",
            "Epoch 634/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.0395 - accuracy: 0.9967 - val_loss: 0.0432 - val_accuracy: 0.9900\n",
            "Epoch 635/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.0409 - accuracy: 0.9944 - val_loss: 0.0593 - val_accuracy: 0.9800\n",
            "Epoch 636/10000\n",
            "900/900 [==============================] - 0s 45us/step - loss: 0.0527 - accuracy: 0.9844 - val_loss: 0.1049 - val_accuracy: 0.9500\n",
            "Epoch 637/10000\n",
            "900/900 [==============================] - 0s 54us/step - loss: 0.0569 - accuracy: 0.9844 - val_loss: 0.0774 - val_accuracy: 0.9600\n",
            "Epoch 638/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.0443 - accuracy: 0.9900 - val_loss: 0.0630 - val_accuracy: 0.9700\n",
            "Epoch 639/10000\n",
            "900/900 [==============================] - 0s 61us/step - loss: 0.0426 - accuracy: 0.9944 - val_loss: 0.0558 - val_accuracy: 0.9800\n",
            "Epoch 640/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.0386 - accuracy: 0.9933 - val_loss: 0.0544 - val_accuracy: 0.9800\n",
            "Epoch 641/10000\n",
            "900/900 [==============================] - 0s 48us/step - loss: 0.0424 - accuracy: 0.9922 - val_loss: 0.0334 - val_accuracy: 1.0000\n",
            "Epoch 642/10000\n",
            "900/900 [==============================] - 0s 48us/step - loss: 0.0571 - accuracy: 0.9811 - val_loss: 0.0337 - val_accuracy: 0.9900\n",
            "Epoch 643/10000\n",
            "900/900 [==============================] - 0s 48us/step - loss: 0.0479 - accuracy: 0.9889 - val_loss: 0.0542 - val_accuracy: 0.9800\n",
            "Epoch 644/10000\n",
            "900/900 [==============================] - 0s 64us/step - loss: 0.0411 - accuracy: 0.9900 - val_loss: 0.0413 - val_accuracy: 0.9900\n",
            "Epoch 645/10000\n",
            "900/900 [==============================] - 0s 55us/step - loss: 0.0423 - accuracy: 0.9911 - val_loss: 0.1193 - val_accuracy: 0.9500\n",
            "Epoch 646/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.0659 - accuracy: 0.9800 - val_loss: 0.0634 - val_accuracy: 0.9700\n",
            "Epoch 647/10000\n",
            "900/900 [==============================] - 0s 48us/step - loss: 0.0378 - accuracy: 0.9956 - val_loss: 0.0460 - val_accuracy: 0.9800\n",
            "Epoch 648/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.0407 - accuracy: 0.9922 - val_loss: 0.0746 - val_accuracy: 0.9700\n",
            "Epoch 649/10000\n",
            "900/900 [==============================] - 0s 55us/step - loss: 0.0522 - accuracy: 0.9900 - val_loss: 0.0466 - val_accuracy: 0.9800\n",
            "Epoch 650/10000\n",
            "900/900 [==============================] - 0s 67us/step - loss: 0.0430 - accuracy: 0.9911 - val_loss: 0.0539 - val_accuracy: 0.9700\n",
            "Epoch 651/10000\n",
            "900/900 [==============================] - 0s 67us/step - loss: 0.0438 - accuracy: 0.9944 - val_loss: 0.0554 - val_accuracy: 0.9800\n",
            "Epoch 652/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.0446 - accuracy: 0.9922 - val_loss: 0.0443 - val_accuracy: 0.9900\n",
            "Epoch 653/10000\n",
            "900/900 [==============================] - 0s 59us/step - loss: 0.0440 - accuracy: 0.9933 - val_loss: 0.0552 - val_accuracy: 0.9800\n",
            "Epoch 654/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.0491 - accuracy: 0.9878 - val_loss: 0.0348 - val_accuracy: 0.9900\n",
            "Epoch 655/10000\n",
            "900/900 [==============================] - 0s 56us/step - loss: 0.0538 - accuracy: 0.9833 - val_loss: 0.0484 - val_accuracy: 0.9800\n",
            "Epoch 656/10000\n",
            "900/900 [==============================] - 0s 62us/step - loss: 0.0451 - accuracy: 0.9900 - val_loss: 0.0491 - val_accuracy: 0.9800\n",
            "Epoch 657/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.0519 - accuracy: 0.9889 - val_loss: 0.0603 - val_accuracy: 0.9700\n",
            "Epoch 658/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.0446 - accuracy: 0.9911 - val_loss: 0.0651 - val_accuracy: 0.9700\n",
            "Epoch 659/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.0464 - accuracy: 0.9900 - val_loss: 0.0569 - val_accuracy: 0.9800\n",
            "Epoch 660/10000\n",
            "900/900 [==============================] - 0s 65us/step - loss: 0.0379 - accuracy: 0.9944 - val_loss: 0.0778 - val_accuracy: 0.9700\n",
            "Epoch 661/10000\n",
            "900/900 [==============================] - 0s 59us/step - loss: 0.0571 - accuracy: 0.9900 - val_loss: 0.0387 - val_accuracy: 0.9800\n",
            "Epoch 662/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.0390 - accuracy: 0.9933 - val_loss: 0.0521 - val_accuracy: 0.9800\n",
            "Epoch 663/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.0457 - accuracy: 0.9889 - val_loss: 0.0584 - val_accuracy: 0.9700\n",
            "Epoch 664/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.0488 - accuracy: 0.9933 - val_loss: 0.0585 - val_accuracy: 0.9800\n",
            "Epoch 665/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.0381 - accuracy: 0.9911 - val_loss: 0.0698 - val_accuracy: 0.9800\n",
            "Epoch 666/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.0426 - accuracy: 0.9911 - val_loss: 0.0728 - val_accuracy: 0.9700\n",
            "Epoch 667/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.0428 - accuracy: 0.9900 - val_loss: 0.0776 - val_accuracy: 0.9600\n",
            "Epoch 668/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.0409 - accuracy: 0.9956 - val_loss: 0.0806 - val_accuracy: 0.9600\n",
            "Epoch 669/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.0435 - accuracy: 0.9900 - val_loss: 0.0390 - val_accuracy: 1.0000\n",
            "Epoch 670/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.0403 - accuracy: 0.9944 - val_loss: 0.0783 - val_accuracy: 0.9600\n",
            "Epoch 671/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.0431 - accuracy: 0.9922 - val_loss: 0.0806 - val_accuracy: 0.9600\n",
            "Epoch 672/10000\n",
            "900/900 [==============================] - 0s 57us/step - loss: 0.0486 - accuracy: 0.9900 - val_loss: 0.0459 - val_accuracy: 0.9800\n",
            "Epoch 673/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.0459 - accuracy: 0.9900 - val_loss: 0.0603 - val_accuracy: 0.9700\n",
            "Epoch 674/10000\n",
            "900/900 [==============================] - 0s 56us/step - loss: 0.0389 - accuracy: 0.9956 - val_loss: 0.0463 - val_accuracy: 0.9800\n",
            "Epoch 675/10000\n",
            "900/900 [==============================] - 0s 55us/step - loss: 0.0435 - accuracy: 0.9944 - val_loss: 0.0556 - val_accuracy: 0.9800\n",
            "Epoch 676/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.0419 - accuracy: 0.9933 - val_loss: 0.0675 - val_accuracy: 0.9700\n",
            "Epoch 677/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.0401 - accuracy: 0.9944 - val_loss: 0.0899 - val_accuracy: 0.9600\n",
            "Epoch 678/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.0569 - accuracy: 0.9833 - val_loss: 0.0331 - val_accuracy: 0.9900\n",
            "Epoch 679/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.0403 - accuracy: 0.9933 - val_loss: 0.0466 - val_accuracy: 0.9800\n",
            "Epoch 680/10000\n",
            "900/900 [==============================] - 0s 54us/step - loss: 0.0447 - accuracy: 0.9922 - val_loss: 0.0530 - val_accuracy: 0.9800\n",
            "Epoch 681/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.0387 - accuracy: 0.9944 - val_loss: 0.0353 - val_accuracy: 0.9900\n",
            "Epoch 682/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.0491 - accuracy: 0.9900 - val_loss: 0.0608 - val_accuracy: 0.9700\n",
            "Epoch 683/10000\n",
            "900/900 [==============================] - 0s 48us/step - loss: 0.0409 - accuracy: 0.9911 - val_loss: 0.0598 - val_accuracy: 0.9700\n",
            "Epoch 684/10000\n",
            "900/900 [==============================] - 0s 61us/step - loss: 0.0422 - accuracy: 0.9878 - val_loss: 0.0693 - val_accuracy: 0.9600\n",
            "Epoch 685/10000\n",
            "900/900 [==============================] - 0s 55us/step - loss: 0.0575 - accuracy: 0.9856 - val_loss: 0.0561 - val_accuracy: 0.9700\n",
            "Epoch 686/10000\n",
            "900/900 [==============================] - 0s 50us/step - loss: 0.0433 - accuracy: 0.9900 - val_loss: 0.0870 - val_accuracy: 0.9600\n",
            "Epoch 687/10000\n",
            "900/900 [==============================] - 0s 64us/step - loss: 0.0394 - accuracy: 0.9944 - val_loss: 0.0621 - val_accuracy: 0.9700\n",
            "Epoch 688/10000\n",
            "900/900 [==============================] - 0s 48us/step - loss: 0.0468 - accuracy: 0.9900 - val_loss: 0.0593 - val_accuracy: 0.9800\n",
            "Epoch 689/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.0507 - accuracy: 0.9856 - val_loss: 0.0563 - val_accuracy: 0.9700\n",
            "Epoch 690/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.0354 - accuracy: 0.9922 - val_loss: 0.0740 - val_accuracy: 0.9700\n",
            "Epoch 691/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.0528 - accuracy: 0.9856 - val_loss: 0.0633 - val_accuracy: 0.9700\n",
            "Epoch 692/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.0454 - accuracy: 0.9867 - val_loss: 0.1105 - val_accuracy: 0.9700\n",
            "Epoch 693/10000\n",
            "900/900 [==============================] - 0s 58us/step - loss: 0.0439 - accuracy: 0.9933 - val_loss: 0.0632 - val_accuracy: 0.9700\n",
            "Epoch 694/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.0398 - accuracy: 0.9933 - val_loss: 0.0640 - val_accuracy: 0.9700\n",
            "Epoch 695/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.0396 - accuracy: 0.9911 - val_loss: 0.0559 - val_accuracy: 0.9800\n",
            "Epoch 696/10000\n",
            "900/900 [==============================] - 0s 55us/step - loss: 0.0492 - accuracy: 0.9900 - val_loss: 0.0536 - val_accuracy: 0.9700\n",
            "Epoch 697/10000\n",
            "900/900 [==============================] - 0s 52us/step - loss: 0.0403 - accuracy: 0.9944 - val_loss: 0.0491 - val_accuracy: 0.9700\n",
            "Epoch 698/10000\n",
            "900/900 [==============================] - 0s 54us/step - loss: 0.0488 - accuracy: 0.9900 - val_loss: 0.0449 - val_accuracy: 0.9800\n",
            "Epoch 699/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.0389 - accuracy: 0.9967 - val_loss: 0.0388 - val_accuracy: 0.9900\n",
            "Epoch 700/10000\n",
            "900/900 [==============================] - 0s 51us/step - loss: 0.0510 - accuracy: 0.9833 - val_loss: 0.0669 - val_accuracy: 0.9700\n",
            "Epoch 701/10000\n",
            "900/900 [==============================] - 0s 60us/step - loss: 0.0395 - accuracy: 0.9911 - val_loss: 0.0617 - val_accuracy: 0.9700\n",
            "Epoch 702/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.0357 - accuracy: 0.9956 - val_loss: 0.0465 - val_accuracy: 0.9800\n",
            "Epoch 703/10000\n",
            "900/900 [==============================] - 0s 49us/step - loss: 0.0391 - accuracy: 0.9922 - val_loss: 0.0784 - val_accuracy: 0.9700\n",
            "Epoch 704/10000\n",
            "900/900 [==============================] - 0s 47us/step - loss: 0.0415 - accuracy: 0.9944 - val_loss: 0.0833 - val_accuracy: 0.9700\n",
            "Epoch 705/10000\n",
            "900/900 [==============================] - 0s 58us/step - loss: 0.0402 - accuracy: 0.9911 - val_loss: 0.0528 - val_accuracy: 0.9800\n",
            "Epoch 706/10000\n",
            "900/900 [==============================] - 0s 53us/step - loss: 0.0464 - accuracy: 0.9889 - val_loss: 0.0473 - val_accuracy: 0.9800\n",
            "Epoch 707/10000\n",
            "900/900 [==============================] - 0s 55us/step - loss: 0.0510 - accuracy: 0.9833 - val_loss: 0.0651 - val_accuracy: 0.9700\n",
            "Epoch 708/10000\n",
            "900/900 [==============================] - 0s 59us/step - loss: 0.0594 - accuracy: 0.9844 - val_loss: 0.0693 - val_accuracy: 0.9700\n",
            "Epoch 00708: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f5332da2e48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuUNVq0OLqde",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = pd.DataFrame(model.history.history)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOjPGBWaL2mQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "9344ba5b-2938-42d3-c086-3f14cdef3b37"
      },
      "source": [
        "dataset[[\"loss\", \"val_loss\"]].plot()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5331f14940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stvmjL5jMoje",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "fe7df159-359e-4259-979f-05b351f27d57"
      },
      "source": [
        "dataset[[\"accuracy\", \"val_accuracy\"]].plot()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5331e144a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2deXhU1fnHP2dmshEgCwlhJ2wi+xZRRBFFWhRFxaLgUmsr1lr8obZatypVtLZqW22tijttFRVrRaTgAqgVRRbZ952whgCBELLMzPn9ce/M3NknYUIyyft5njxz77nn3vsmmfnOe9/znvcorTWCIAhC4mOrawMEQRCE+CCCLgiC0EAQQRcEQWggiKALgiA0EETQBUEQGgiOurpxTk6Ozs/Pr6vbC4IgJCTLli07pLXODXWszgQ9Pz+fpUuX1tXtBUEQEhKl1M5wxyTkIgiC0EAQQRcEQWggiKALgiA0EETQBUEQGggi6IIgCA2EqIKulHpNKXVQKbUmzHGllHpOKbVFKbVKKTUw/mYKgiAI0YjFQ38DGBXh+CVAN/PnVuCFUzdLEARBqC5RBV1r/SVwOEKXK4Dp2uBbIFMp1TpeBgqCUEsc2wsb5tS1FTWjeCts+czY1hq+fRG2f2Xs71sFuxbHdp1Nn8CRHbHfd9sXcGhLtUw9ncQjht4W2G3ZLzTbglBK3aqUWqqUWlpUVBSHWwuCUGNe/QHMmGAIYj1h2c4jHDhWTtR1Gp4fDP+82rD9wBqY+xuYcb1x7KXz4bUfMHnG91Q63d5TPNdctOUQ+0vKjca3xsFfC/yOR2T6GPjboNj6mny3/TCHSiuqdU5NOa0zRbXW04BpAAUFBfXnXSQIjZES0w9zVkBSKkXHKzhWXkWX3KYs33WEHq2ak5Zsr9Gl95eUU+F00bFFesjjTpebqR+vZ8LgDizaeoi9R09y0Zl5THj5W2+foV1b8MvhXTm3a07wBdxO4/XEITi83diuKOGWN5fwitnlwxV72X24jL9cO4BpX23ln9/u4p4fduepeRvJapLEAz/swjgAdxX/23yIG15dzL2jurOruIzJF3ejdUYa7y3dzdaiEwzulIXTpfmBee273lnB7FX7uLxfG3KbpZDfIp2xA9sy9eN1/HxYF5qmOFi68wibDhznqXkbvWY/N2EAY/q1qdHfNBZULN8aSql8YLbWuneIYy8BC7XWb5v7G4HhWut9ka5ZUFCgZeq/0CA4uhvScyEptVqn/f4fs9lta83fL8lmXmESKSnJDO/ekre/20Vb+1E2H1X8YEAX2mc3YffhMvIcZSQ7bNAkmyMnKtHA2r0l7D16kh/1b8W+XVto16Wn9/qHT1Sy/dAJerZuzuGyStpmprH7cBnHy510b1aB/ZmuAHxz4TuoJtmMf994av7F8C68sHAroPnkx+34YFcqK3cf5c8/yOLY8WN0bJmBLbsL+45V0C4rja1FJ/hyUxHDzsjh7zPn8d9digxOAPCP687g9a3pHNpfSFllFW2bOejdoycvz5qPHTfbdWtSqKSv2sYOnUeeOsJJUnBhY6/OIZej9G+Txp8vb8f35W2Y+s6X9O3Vi8fXjgDgf13u5tCu9VxZ9V9KdSpjKqcyP+XXAPQpf4UsdZzMpmlUlh5ln86ms9rHfp3NEZrSlHKWpv4CgLPK/04RmQB0Vntpk5XOmIvO596Zq/z+ZztSrwMgv/wtANqpIip0Ei5sjDm3L28s2hH0f25NMYdpRgXJAGyaeonxf6whSqllWuuCkMfiIOijgUnApcDZwHNa68HRrimCLiQSB46V87/Nh7h6UDv/Ay4nPNYCel6JHvcGR8qqSEuy49aa9BT/B+BVhUc5WlbFsDNy2fjlu3SfP5GHqm5matLrvOK8hKnOG7EpcGtDONa483m07Yv85dr+nPvkfK+Y/OW8Jfzls81+13651QeMPPoeRT9fzaytLm44pwM3vvod3233DX89NLoHUz9eD/iEycpFFU+zTfu8xxvsnzI16XWuqHiUlborG1N+TIoyPOPHqq7nVddozu+Ww1ebDwHwI8dXPO14gcXuM+ms9lJJEm1VMQXlL3iFEyC//F/sSL3euz3Z/m/uSno/6v9gs7st3Wx72OXOpYMtOGRbqlNpqsrDnr/e3Z4eNuOp5CtXb6Y4b+LzlHssdr3F2Wo976Q8BsClFU+wTudbrqAtdr/FmD4teW7zxX7nB6Jwsz31Bj51DWRilfFF88jlPbl5aKeov284Igl61JCLUuptYDiQo5QqBB4BkgC01i8CczDEfAtQBtxcY0sFIc7sPXqSzQdLueAMX3G6skonCzYUMbqvMXbvdLmx2xRKKQA+XXeAwfnZZDRJ8p4zcfpSVhWWcOGZLclOT+a9pbtZvusoD1+URxqg189i6JPz2VviE5Q//qgvPVs354k560lx2Fiw0RChF28YxI5PPqS7A4bbVgAwwracqdyIWwMYTlZv2w6OnKjk3Cfn+/1OgWIO0OrwErDBz597n+X6DB6bvS6oj0fMw5HFce/2ma2acWHFXjhp2LHS1dUr5oa93/Oqa7RXzAGGKsObHag2k6Rc3vZ85f+wnkqld7spJ+lsi/gw76WbbQ+AV8zvcU/iKdvffNeKIOaAV8wBzrevIcN5IqjPS6PSYIHH7v389pbxuNyaTQeOM65/LjxtHPto0nmk61II/ld4mXh+J37aJxleg5H25XwyaRi3/2s5v/toHaP7tKZl8+o90cVCVEHXWk+IclwDv4ybRYJQTTbuP84/v93J78b0wmZTfsdG/ukLTlS62PDYKFIcNpRS3PXOCuatPYDT3Z8x/drQ9cH/csM5HZh6ZR8WbjzIxOnGk2OL9GQev6oPo3q3Ys+RkwA8/clGTla6+OB7Q1y+WbKYhSngdms/MQe4b+YK3CHyDm775zKedJQCkKtKAFCADTdubDSnzNt380Gjnw3f4F4KlVThwI1CmeJfoo1YdTtVxGrdGRc23Ng4Kz+LJTuOxPR3bKrKaZrs4O/XD2RY12zmPjsdTkImpVzQpRns8fXNUqVeez14wixWMQe4Z3AKrPTtZ1Lqd07ftGIsGh8TJ3L68dStD8ITf4veOQxn5Sk46t+WqXx/+55NSxnSpQW4XZzXJRsqSrzH+rRtTnmx/8l3XNSVwZ2y+cc3O8ltlsIvL+xK5sElABzTTchvkc7gjhlsOVjKnNX7+MkpeOnhiCnkUhtIyEWoDgs2HOSW6UuZO/l8yipdzF61l1/9oDupSXYe/d1veFi/yJIJa8jKyuTZz7fw0cq9/K3vdi7b9CD9yqfx6yvPYfqiHfRvn8l7ywq91/3inuFc8NRCAP47+Xw6vNiVRe5ejLQvZ1zFwyzRZ7LsoYtxPN2Zj52D+cg9hLeTH2dsxRT+nTLFex2XVnSp+Jd3f7jte95IfgqAOa7BXGr/znvsI9c5XG73Df5F4kPXuVxhX1Tjv5vzqpdxfDCRr129GGpfa7RpGw7lDuqrr34Vel+NWvk2/OcXQcdD8euqn/NAszkUZgxCFa2nj3tjcKehd8LXf6nx7xCSXmNh3OswJaPGl9AtuqGKI7jYgWS09w0kh+KRo/DujXB8P9zyGbz3E1j7QVC3XYMfpsOlv6q+wSanFHIRhLriWHkVf5y7ge55zXhh4VZcbs3IP3/pPd4trxnXFLTnFve7oODO1z+nJKU1pRVGaKD1hjfABj1su/jtf5oCPo/Xg0fMAS559kt2pFYw0r4cgLH2r1jiPJNBUz9jR2op1znmk+MyvLRr7QuJxJnK98G3ijkQJOaHdVOylb9dHk5FzAEcC6YCeMUcCCnmAKr8KCgFu2L7sgGYkFdI9uHdZJfvRuecAYdCdNq3IvqF8nob6YexkpVvvN48l99N+xfplPPrpPdiPx9QZYfQzdpASnPUoQ3+B1v2hIMBYatIYg5QWQrrP/LthxBzgA7HllfLzuogtVyE00Kl002F0xWxz0cr93LkhPHsXVbp5Jl5G/nnt7v47Ydr2XcsOD5678xV3P6vZSRhXDdJOb1iDr4wRA4lQeeGIo0Kv/2BHbOC+gzKM0I6VQSn83XO8aXoZajg+Gw4Ui+4O+a+1eZo2LUQgikvqfY5g+xbvduqZE/oTvtWhm630umCmO8J+AS94xC6X3Ev6a26+h/v9oOgU4I4eQQ1eCKq74/825u3g0v+ELstva4yr2cJwVSWhe4LcDy2MYOaIB66cFq4+oVFrN5TwoJfD6eTKXzfbT9Mzs7ZNDmxm7LBk7nj7e8Z2TOPZ67pR98pnwAwUG3iN0kz+H3VdazA/0N7oe17eq/fSJLdEPGJ9jl0VPvp1CaXlvu/8sZyJzn+QxvXIaa5LgdgUMcslu30xZUXn/UFyVXH2Xu8yi9O3D2vGWwFzyAlQLbN+KDe4Pjczxa70rxc+RtWJ2XTUR1kgC322YRN0pvG3Dciyc2g8jikZkL50ej9LWhbEuq7V+C7l6snOEUWz7YqzJfYyRhi+M2rObncI+jA+MEdoHlfmGHtoALPCH+dYwFfRCnN/K4flebmPMq/WJIAXx0Zvv+eZbBuFvQcE/s9YkQEXTgtrN5jeH8XPr2QK/q3YdHWYoqOV7Aj9Q4A8r/qD8D3u47w7dZi73kj7Ms527aBobY10KaA8ioXG/Yb2RivmzHqCm1ko1zvEdkD+H2ez7Tt5gHb29w/9QWW7zpK77bN6f7QXACeGNOdvE+MFL5gfxyaJNupqvR57qo8wNtPy0KnZrHZ2ZKuFWvoYg94dI/EeXdDm/7QZQRs+Rw2zzPah95phD12hwh9jPoDrHwbOg0zhCG7M3z/D/MXHW2I0Rmj4F9Xx24HoJq38ffM+98AB1bDuf8H8x6A0gOhT+w6ErZ8atm/2DclHyCnOxwy4+odzoWMdrD63eDrFPwUdi6CpDTj5/t/Gu0Z7aHvNUYIJD0Hti00niTaneV/fruzoMcY6H21cZ2h/wcle+A101PveQUMmRQstFn5UOZ7v9FmAFz1kuGlD7rZuFb3SwzRXx0mpNN1BHxjGZy1JUGzVpDcFCpPQP55sH+V4cF3Oh8ObwNHSuhrnSIi6EKts3yXv4f24Yq9YfseKq3k1n8s8+57dNmGm4t7tOSXF3Zl3toDtGiabJSNA1JUVUx2KGcFg8wwyo4nR6O1RhVvhU/CnOB28sldwyguPgSmvlAWUNboVxtRjhTOAHjtEti1CPL6GGIYiatfhT6WR/1xr8MTZg74yN8Zr4tfgv/eC+feAYv+arR1vwTOuc3/Wln5MP8xQ/B++Dgci+BhdxkBW80vvgsfAjPGTla+v6Bf8Tcjng6Q1MQoEZDZMTgcc8NM2PkNvG7W7xvzV/hTD9/xvJ4+Qb/uHUhtDtu/CP6CSE6HCW/79j2Cfudqnx0AnYeH/r2a5sK15hdbryuN1wzLnIErnje+7ALJyocDa33X/vGHvmOXWwZy3S5/QR90Myx73djO7Oj/t7ntK2hp+RucRkTQhbhR6XRzstJFRpMkqlxujpRVGil+y32PtO3UQXqrHRzuOIq2mWlgpka34RAFtk3Mcp8LgB0Xv7DPYkLOdjgKl3VNpot7Burjw4xKDj2dPCrv3QS53UG7QWuUs8LfOwtk17e0+/pB2lkzwZwn/ftYPa20TPOX6R9d0AMf6ZOahO9j7ds8RJkkT3jFc3/Payisx5pk+7Yz2/v3s4qoq9J371Dxdat9qQH3zuvlGxxMbW682pKIGRVj6CQaocQ8JQPSsownAgBHhLxwW8CYSXI6JKUbYabA/11mx1Oz9RQQQRfixt3vGvUttjx+CZNnfM+c1fsB6NiiCe2z08hvkc7zu26huSqj6pZH+PfyQq+gf5k5BUf5YWaXn4MbG73VdiNrwdSq7sXzYadxPWxJ4A7jlTdrA85y86cCtGUgdtNc48dKJHE5uguWvubflpZlXLeqzPB2rdjNa2V3Mgb5dn1jiGG3H/g8+5xuRlXA3O7+5yplPO73uNzX1mYA5J4JHYfCRQ8ZlRHtIT6y/a4zYt+9TY8/Kc0Q3/PvhvWzYdsCSM2A8mMwdDIULoGKUugwxBDj1v2g84VmhobyebgeOgwxROviR4xUvIt+a3innYYZx5vmQVYnGHaPce+mraDftbBxLvS8EpZPh/bnWP7mpjh6wjEDbwr+nfpcE9xWE875pX+cv+tIY4zgwBrI6uj/hREtDHLWRFjysrHdfjC0HQhz7jW+GEc9aTzF5HSH5BBfzqcJyUMXYmZXcRkaHbLgktaaTvcbpVgv7pHHZ+v9H6nP6ZzNlDG9OPNF0xOcUsLmA8fp9oL/VPru5W/wzW9Hc/fjT/FG8h9DGzLmr7DgidCDd1MCYtwLnoAvAjIW2g2GQjOVcOzLsPlTX1y360gjjACw9HWYfafvvMAwSSDTrzBivD96zYjlCqH56yAo3mKENzoPP/33378GXhxqxNyv/Qd8/y/48Hboey2MnXb67akmkocuxIVhTxlzonc8ORqAk0U7eHVJEaN75tCyWRJNKSNTlfLZeuio9pPBCdboTnRVe7hQbSf3sGU64L5VdGvVJ+ge7VQRme6jjM3dQ9hsw8DH+khE87qS0yHFkmViDUkEhi4iPZKDL5ujebvI/Ro7NlN27LUzMBgVjwftCRV5wmjR/r8JgAi6UGPSnu/HBN2MFt8ZWSfvJRvFj/LL3+KLFCO3+gXn5Vxv/5zme8rAmtzw0vkw9pWga36ecg88cw8RE7rCxYj7jg9uc6T57/caC+0KfB56UhP/wbPul1ruE5D3Eu0D3320kXOd3Tlyv8aOJ8zlSK6b+zdpYbwvWvcz9vNMx6LLRXVjTxwRQRdiYvYqX2aKy62xmzVTWihfQSdf8SNfGG+IbR3pBAwkeiiKXCwqLKE89AsfgvPuCm4P9NCvesmIdc97wNhPTodzJxti3CQbmrYMf59o3v6we+CsWyC9RfTfoTHjHQeI04BndUnNgLvWGMIO0OFsuGerkSWU4MhMUSEk3+86wkP/WY3WmiMnKpn01vfeY0/+dz1TZq0Ne67dUkgqlUrsKsw4jarZ4gkhPfS0zNADhkkBHroj2X8gLDndOK/lmf5iHuo+0TIubDYR81jwhFzckWcO1yrpOf7/zwYg5iAeumBh7d4SPll7gDsv7sb4ad9S4XRTctLJ2AH+qXIvf2WsEDMlTATCKuhdMhUcC3PDwFSwWElp7tvO6AAlu4xMi1BE86pDpQuGug+AEv8nLuSeaWTa1GE2SENFBF0A4ONV+/jlW0bRoNsu6OINmny0ci+HT1SEPzEEz1/bC8z5GUmemtM2h2/ZMC/VfOS++lXjMTkt07cO5nmTjTS5M0eHPscTQ0/LNirgBRIpp71JNtz4H2jV15i12WFI9ewVQnPpU0aGSV6vurakwSEuhwDgFXOAT9bt91tc9+stvsk3BSEKVgUy8gxLn0qLoAcSJPABtOrrv9+8DXS50L/NngI9LgsfDvF46Hm9oEWX4OPRJil1udAIo5w5On6TXBo7SWlwRgzFs4RqI4LeiDlZ6WLumuBc7skzVqBw80rSUzzsmO53rHfbDN6eeE7QOX44y4O3QwmnM/IKM0Ex7FDhkWhhm1BfJNb2wCwYQUhgRNAbMY/OXstt/1zOnz4JXpSgGWVcbP+enzqMmZXDzCXcWmWk0rVllOqAzhAhmnNuD26LNO0egrNMkkPcN9rAqifurQNqgN+6EEY+ZgxkCkIDQWLojZjth4xwyHPzg0u9JuOfgfCjQe2YeH4nhnRugcNu4/NfXQDPh7lwVYg0xZTmxqzAbQt9bdHKtAZ66NZBNE/4I5qH7ukXKOit+hg/gtCAEPekEbM/YA3M/BY+wXTgi2+Psn1H9vFNnN8tF4fdeMt0yY3gpYfy0G32YG/6+P7IBgZ66KFCLtEyT8J56ILQABFBb2SUV7lwutz8+r2V7Cj2X1XFE1YBGN3Tl089NeVNCg5WY3mvULFxmz3Ym44k6PYUX3U+D6Hi8NE89FZ9ID3XKG4lCA0cCbk0Eqpcbn7z/ir+vXwPaUl2TlYFT+q4pqA9G/cfZ/H2w7RM933X56TZQAcsy+6O4PEGlpgFwzsP9KZPHg7u5yGrI9gDpobbQ1RGjBZDT2kG98S+epAgJDLioTcS1uwp4d9mXXKPmLdTRbTEKCj18KVn0Jst9O9ghDnSbBbBdruCvW4dYZZfyJCLI7z4poRYuT0rP/R1gq5bw8lJgtAAiUnQlVKjlFIblVJblFL3hTjeUSn1uVJqlVJqoVJKys3VI+at3c9Vfw9ePf5/KZP5LvWXAFxa/Aa8fBFtyw1v1qEsOeJaB4trpGnb4UIuofK4lR3SQgh687a+HPZI1LR8gCA0QKIKulLKjpHPcAnQE5iglOoZ0O1pYLrWui/wKPD7eBsqxMaHK/ZQeMSIjf97eSE3vLKYv87fHKKnr76Kw6bIKzUKZTV3GmEQ7bSEWHQ8PHS7b3anlbRMXxnVq1/1LfDgSPUJ+g8ehwfDxNsl7VAQvMTyaRgMbNFab9NaV2KsrX1FQJ+ewHxze0GI48JpoNLpZvKMFVz5/NcA3P3uSv635RAnKoLFd0xXXzx6ze9+6J2E76miqF0WQXe7/EVa68izPEN56MqO9UvES0pzX2y8eRujEh4YXwBV5qBtakZwkS3Pl4N46ILgJRZBbwvstuwXmm1WVgJjze2rgGZKKSk7d5o5WmaI8KFS/wFMT765le4pvgHJ1CSfKDrMyog3rLdMBHI7wWUKuqsKfpcJn/0uvCFVYUIuoTz0qpM+Qbcl+QZObQ7I7GBsZ0VYo1Fi6ILgJV7Pq78GLlBKfQ9cAOwBgtxCpdStSqmlSqmlRUVFcbq14OFImW+dzSfmhK81/sy4flzf36y3kuSfCpgcmM0CxvqdHg/d430vfTW8ISFj6A5CeujlRy3ZLNrncduT4PxfGcWxPGtXhiLc1H5BaITEIuh7AOuS4O3MNi9a671a67Fa6wHAg2bb0cALaa2naa0LtNYFubm5gYeFU+RImU+Mp325LWy/qwe1I9Nhin+Sfw3czplhClB5RDqWNWjDhVxCness961g46r099DtScHFuLzXU77rCoIAxCboS4BuSqlOSqlkYDwwy9pBKZWjlDfJ+H4gYKl04XRwtCzYu052hPkXewYcA2ZfdmqmWfrQxcH9PR56pMFQb98wIRerh55uLiZhcxhlasEUfG3pHwMSchEEL1EFXWvtBCYB84D1wLta67VKqUeVUp6lH4cDG5VSm4A84PFasleIgDXk4uH24f4lY/86YYCx4RX0gMHGqjJymoZYFMIj0pEmFHn7hgjbBApvUiqM/hNMnA+XPwfD74eOQ31T9GMNpciiE4LgJaZPjdZ6DjAnoO1hy/ZMYGZ8TROqS2l5cObJJb1b85fPjLTFDtlNuLxfG+OAJ4PEs/CxR0gry8KERqrjoYeZKWq9rrLDWT/z7Q83pzd4+thCzAoNhXjoguBFRpQaECcqgwW9e6tmbHn8Ehx2G1Uui3cd6KF7PPDK0tCFrDyCHm1RCmtfKzaH/3XDCXG1PXQRdEHwIM+rDYiySn/v+cFLewB4KyQm2S3/bu8sTHNwseK48eqsMFITA3FXGfnosSzsW1UW3BYYQw8bKpEYuiDUFBH0BsSJCp/3rBRMHNY5fGev6JoCetJMStKu8F64syI2Dz3UlP3APPRwHriOcjwQ8dAFwYsIegPC6qH3ST4Ax/aG71xpCrp2G/2OFRr7bhdsWxD6HGd5bHXFQwl6oPCGE+LqhlzEQxcELyLoCc7yXUd4fsEWtNZ+HvosdRf8qUf4E6ssgv5sP1/75k/gnRtCn+OsiC3kUlka3BY4sWjA9WFO9kzpj/GtKVkuguBFBkUTnLFmFcWrBrRlS1EpDpvC6Y5h8o8nW0W7jQk9HqyLTrQ/G3Yv9u07y0OHXBxplswWFcZDV76Qy4QZcMaoMHbFKOi6mrF2QWgEiHvTQPjr/C1sKzoRXsydFf455J7twBRFhyUHPXDJN1dl6LRF61qfjlRfOMeK1r5wij05dCld8PWJ2UMXQRcEDyLoDYS3v9sVucPUlvChpeCW1UO3Yl0lyOFfFiCsh263fAk4UqLXMY/kVXsFPYzge/BO/Y/STxAaESLoCYwOMQHoyv5t2PHk6MCOxuvKt31tnli41tBmgFGkK7uL/zJvjoAl4AK9fA8Vx3zbSWmhY+h+hbkiibCOoY8gCKEQQU9QXG7NM59s8mu7sn8b/jJ+QHDnUF61N3RirkbU5UJz4NIipKE89FAhF6uAO1IIWVVRa0t8PIJYx9JHEISQiKAnKJ+s3c/fFvgvftwiVA0W8J+5+d7NxqsntKHdhlA7Uo1QiFX8HQHXC5eHbo1jH9sX2ga/LJcYPPRogp5mFvSSLBdB8CKfhgRix6ETLNhwEIAtB4PDGtnpyUFtgH8Wy9p/G69uSwy9yhR0ZfMXbHtgyKU8OG2x11i4/l3LvUJM+2/aClr2iNFDj3FQ9Pr34NKnoVmryP0EoREhaYsJxBNz1vPJugNcW9Ced5buDjoek6B70JYsF2e5Uf1Q2UJP+/cQykPvM86IvUfinNtMEY/BQ/cO0kbx0DPawuCJkfsIQiNDBD2BKDxi5Hq/v7ww5PHWGanGoOWCgOrFoYplWT10Z4Ul5BJF0ANj6BXHY88Flxi6INQqEnJJIBx2Q+TC5Zp3b9UMCpfAV0/7Hwj00LW2pC26jElBjlSzxK3bv58VZ3lwlssZP/SPoV/6tLF0XOD9jA3zNQaxlti4IFQb+dQkEFYZHDvQt063zTzQqnlq8IIVEOyhW6fwu6oMEfd46H4ECnpAyOXSpyEt0/+8wRNhxMOEpDoxdElbFIRqIyGXBKLC6fOOc5v5MlDe/fkQWmemoQ6sgbJi/5NWz4Tmbfzbqsp8HrqnpktSavCsy0APfcNsOOsW375nJmk8Z2tKyEUQaox46PWcLQdLyb/vY77ecshvAYvmqb4JQG2z0mibmQYvngf/uNL/Au//DD4OCIFUnrCsUGTO6vRkuVjpcI7//s6v4Ys/+PZTmxuvscbQB95ovGZHKOvb9xrjtVWf2K4pCIIXEfR6TIXTxTtLjCn9n6zdz4kK34Bk8zSfoGc1CZPd4uHgOv/9yonJDxMAACAASURBVBO+WLhnpaK0LLAFvB1adIPOw/3bii2575kdjddYvemBP4YpJdC0Zfg+vccafTI7xHZNQRC8SMilHnPvzFV8uMKoaZ6RluRXHrd5qu9fl5pUzZBH1YngbJXUzODQSeXxYK/dOmialW+8Rg25xFD9URCEU0Y89HrMJ2sPeLcddptfDN3qoVebyrLgCUKBg5tgzMaMJOiRQi4te/m2W3Srua2CIMSMeOj1GGskI7CaYlJgeKQ6uJ3RPfSxL0PrvuG975s+shgaos9P58KJIqNwV5sQ9WUEQYg7Iuj1kN/MXMWCjQf92vaVlJPZJImP/+98/jh3AwM7ZvL0uH5UOmNYEi6QUIs9p2X6e+MeEQ6XD271ukN56KnNfR68IAinBRH0esTXWw6R4rB5p/U3SfYXyg7ZTWibmcaz4wfAl0/xo3Wz4Lavqn8jtzO4Dnpqhr8we4Q83ICnX19ZZEIQ6gMxCbpSahTwLGAHXtFaPxlwvAPwJpBp9rlPaz0nzrY2eK5/ZbHffqCUts+yrAw0f2rNbxQo6DaHUQfd6o17F5AI46FbRVxyxgWhXhA1EKuUsgPPA5cAPYEJSqmeAd0eAt7VWg8AxgN/j7ehjZHAGf5nd86Oz4V1QMjFZg6w1thDF0EXhPpALCNrg4EtWuttWutKYAZwRUAfDXgCphnA3viZ2Hg5WeUf576sb5swPatJ4KCoZ5UiFUrQw7xFZHFmQah3xCLobQFrrdZCs83KFOAGpVQhMAe4I9SFlFK3KqWWKqWWFhUV1cDcxk3Y8rjVJXBQ1GZG3kJ56CMfha4jg6/hCFEzRhCEOiVeeegTgDe01u2AS4F/KBXs2mmtp2mtC7TWBbm5uXG6dcPg/WWhS+J6+Pft58bvZmE9dGsM3dzOyocbZgZfwy7j6YJQ34hF0PcA7S377cw2Kz8D3gXQWn8DpAI58TCwMVB4pIxfvbcy7PEW6ckM7JAVvxtu+wLKS3z7tgghF0EQEoZYPrVLgG5KqU5KqWSMQc9ZAX12ASMAlFI9MARdYiox4nRFnhr/ywu7xveGq2b473u8bVsID91Dv+t82wNviq89giDEhaiCrrV2ApOAecB6jGyWtUqpR5VSY8xuvwImKqVWAm8DP9E6sPaqEI4ql39OeDNLnZZXbyrgp+d1ql0DYvHQr3rBtz3mudq1RxCEGhFTINTMKZ8T0PawZXsdMDS+pjUeArNZOuc2pUmSnbdvPSfMGXEm0qCoIAgJg3xq64gvNhWx56ixRujJSn9Bd7ndpKecYlqgtThWNDwhF5ksJAgJjQh6HXHTa98x+jlj2n6gh15R5cZuq6agBka4fliNmaS2CFkuVu7ZavwIglAvkdyzOsBlTgE9WlYFQHmAoJdVunDEWk1Ra8ObDhR0WzXK69ojzBS1ki6JS4JQnxEPvQ4osywlB1Be5Q46HrOHvuodmJLhWxvUg7JFn/zjCbHE6qELglCvkU9tHVAWEDMPDLkYHnqMgv7pI8Zr6QH/dqXg9m8in+sp0OXxzE9lUPTHH8Lt31bvHEEQ4oqEXOoA61JyWuugQdEKZzVi6B5RDiyHq2yQ3QlyzoBDm8KdbLzYQg2KVlPQOw+vXn9BEOKOCHodYPXQO90/h6FdWwT1cdhjFXTzWkFp/57yt6ZIO1J9C0IHEg8PXRCEOkc+tXVAYMjl6y3FNb+Yp8iW2z8u7xVkj0gnRYinB8bSrecLgpAwyKe2DjgRMCgaiopYl5bzeOauCv92Tx65R9AjDZB6RT/Vcr68NQQh0ZBPbR1QVuGK2ifmtUI9IRdXVcCBgJBLRA/dfBs4rIIuE4sEIdEQQa8D4uqhe0Iurkr/dq+Hbg6ThBJ0z0LQNkucXRCEhEUEvQ4IJdY5Tf0Xr4jdQzf7hRX0MGJ9w/vQa6zZxxG6jyAICYUIeh1QURUccslpmuK3H1HQreEVj6A7AwXdMygaRqxtlkWhVYgYuiAICYcI+mli8bZiLnhqAWWVzpAe+nldjWn1Px7SEYBKVwRB//hXvm0dJuTijaGbr46A5evsScGZMOKhC0JCI3nop4nH56xnZ3EZmw+UhhT0ET3yuOncfA6fqGT6NzupcEYYON0017cdLeTiNo/b/Z8AsDksYp/q/yoIQkIign6aefjDNbTOCB6g1FrTPruJd8A0cgw9RAZKkKCb3rfHgw/00G0O3zmeAVMRdEFIaCTkcppZWVjC3LX7/dquHtiOgvxsAFLcFexIvY6RJ+fC79vDf++L7cLOgDx0j+h7smACPXR7ElQZ9dhJamK8OgL6CIKQUIig1zFKwTPX9CPZYfwr2qWcAOD/kv4DFcdg8QuhTwokMA/d46HbTc88yEO3CrrpmUfKVRcEod4jgl7HJNv9/wVJDiMKlhJrLRcP4WLoHpEWD10QGjwi6HWMxzP34vGsrbVZjuyE6VfA+tmeTsEXWj499HW8gh7goTsrfDXUvTF08dAFIZGRQdE6JsURsHaoR4g93jPAnmWwbSGUl0CPy0KHXA5tDGjweOim9+2p9dIkB3pdCbndfdUXPUKenF7TX0MQhHqACHodkxLooXuKbVWesLSZGS8nj8Z+4cCQS6XpjWd1hNHPGNvekEua/6sgCAmJhFzqgGaUcY19ATbcXK3nhZ75qS156J5MlYrjZkMM8XWPoHu87sAl6qxtHi9eCnIJQkITk6ArpUYppTYqpbYopYLy6JRSf1ZKrTB/NimlquFKNj7+nPQ8f0x6mYcc/+Tuihdh0V99BwNXHgKfuHsFPRZMce5/nfF63p3G6/m/9nUZMsl4bTuwGtcVBKG+EjXkopSyA88DI4FCYIlSapbWep2nj9b6Lkv/O4ABtWBrg6GPbTsAY3ukw2ag3PL9F0rQvRUVzTh4LJ60Jxaf1wumlBjbnlcPXUcEtwmCkLDE4qEPBrZorbdprSuBGcAVEfpPAN6Oh3ENkQxKyTMfYDKTzEwW62ISoQTdunScdbA0EhI+EYRGRyyC3hbYbdkvNNuCUEp1BDoB88Mcv1UptVQptbSoqKi6tiYkWmveXLSDo2VGnPy7lNt9Bz0DldEEfY4lTLLkVWKKocfUJwQtutbsPEEQ6px4Z7mMB2ZqrUNWltJaTwOmARQUFASuatwgWbbzCI/MWuvdT1GW/PKqUIIe5c9y4mBsN67pEnK3/S9E5UZBEBKBWD71e4D2lv12ZlsoxiPhFj+KjgfWWLEQUtAjFOWyJ5upizF8F9Y05JKUBqkZNTtXEIQ6JRZBXwJ0U0p1UkolY4j2rMBOSqkzgSzgm/iamNgcKw9c69OCJx7+xR9gSobhnUcSdFclLH8TSnaH7+NBFnkWhEZH1E+91toJTALmAeuBd7XWa5VSjyqlxli6jgdmaB0tZtC48MTOQ1IZkBvuqows6NVCBkUFobERUwxdaz0HmBPQ9nDA/pT4mdVwWLrzSPiDVSf89ytPxC7ozdvCsXCRLyTLRRAaIfJcXotorZm/IcIgZmAKYuUJ+Pju2C4ebTEKCbkIQqNDPvW1iNOtcbkjRKACp+NXnoDdi8P3v/JF33bU1YXEQxeExoYIei0SuHboZ3dfEPmEwBBMIF0u9G1Hq10uIRdBaHSIoNciFVX+6fhZTZIinxA4SGpF2YxVhjxEDbmIoAtCY0PK59YSb3y9nW+2Ffu1ZaRFE/QIHrqyg81SOz2qhy7f1YLQ2JBPfS0x5aN1zFt7wK/NYY/y5w4MuVhF2eYwfrwXMz10ZRH5hw9bT47dWEEQGgQi6HGmvMrFur3HanZyoIfuqVMOhrjbLR5+qIWdrR68hFwEodEhIZc487f5W/jbgi1+baN6taJH6+bRT64o9d9PSoNKs027QnvojlToMAS2fOp/roRcBKHRIYIeZ4pPBBe2unFIR4Z2zYl+siuw7ovFy9Zuf5H2xNCTmsCEt41Fn8OdKwhCo0AEPc7kNQ8erAxaNzQczsAvA0sOu9vlH0bxeOhJqUYoxh4w4CoeuiA0OuRTH2dOVgVXDk5x2EP0DEGgh24tixNYkdgTfgmXvigxdEFodIigx5mKquBaLClJsXroFkEf/Uzkui6eY9aBUz9E0AWhsSGCHmdOVrpo2SyFxQ+M8LbFHnKxCHqrfkSse+5ZZzQpnIcu/1pBaGzIpz7OlDtdpCXbyWtuCO1ltm/Im/vz2E5e8rJvO5oge46nZYU5Lh66IDQ2ZFA0ThQeKWNfSTnlVS5SzZj5k2P7MH7OdbC5BhdUKvJydN1HQXI6DPllmPPlu1oQGhsi6HHA7dac94cFgFGvpUOLdADGD+4QUEW+GihbZEF3pMGI30Y4Xzx0QWhsiKDHAWtmy5GyKo6UHQ3utGEONGkR+0WVjYgx9MA0RUEQGj0i6HHgRIUzeqcZE6p30WgeetjsFkEQGisSaI0DpbEIenWJ5qGnZcb/noIgJDQi6DVEa80f525g7d4STlT4T/oZ3af1qd9A2SLnoaeKoAuC4I+EXGpIhdPN3xdu5e8Lt9IpJ93v2PPXDzz1GygbFPwUvvlb6OPh8s8FQWi0iIdeA05UODlS5qu7sv1QlKXjaoKywcjH4N7t8b+2IAgNEvHQa8CAxz6l0hkhHBIPlAKbDZpk1+59BEFoMIiHXgNqXcxBJgYJglBtYvLQlVKjgGcBO/CK1vrJEH2uAaZgpGas1FpfF0c7E4acplHW+owVq6D/3wrfRKHJq4iY/SIIQqMlqhuolLIDzwOXAD2BCUqpngF9ugH3A0O11r2AO2vB1nrBvpKTQW1ntmrGB7efC0Bus1oQ9OxOkJVvbGd19G0LgiBYiOW5fjCwRWu9TWtdCcwArgjoMxF4Xmt9BEBrfTC+ZtYPTla6GPL7+UHtw87IJbNJMgCj+7TyHdj9Xc1vJiEXQRCqSSwhl7bAbst+IXB2QJ8zAJRSX2OEZaZorecGXkgpdStwK0CHDh1qYm+dcvB4ecj2Ub1b0SknnS/vuZD22ZZFm/euqPnNairov1gE+1bV/L6CICQs8cpycQDdgOFAO+BLpVQfrbVfUROt9TRgGkBBQUHCBYIPHg9ct9Mgy/TOO7QImI7vCl5fNGZqKuh5vYwfQRAaHbGoxh6gvWW/ndlmpRCYpbWu0lpvBzZhCHyD4sCx0B56tinoXtxuWPB7OLa35jeTkIsgCNUkFg99CdBNKdUJQ8jHA4EZLP8BJgCvK6VyMEIw2+JpaH3g4LHQHnqz1IA/4+5v4YugRKDqIYIuCEI1iaoaWmsnMAmYB6wH3tVar1VKPaqUGmN2mwcUK6XWAQuAe7TWxbVldF1RcrIqZLvNFlB73B28UHS1kXrmgiBUk5hi6FrrOQQs1aC1ftiyrYG7zZ8Gi6eq4vm2VSxy98KFnXd/PsS/0/41cHz/qd9MPHRBEKqJqEYMlFe5eOTDNWw6cJyz1Xr+kfwkkx3vA5CfEzAQ+uJQ+Pct0S8abbELEXRBEKqJ1HKJgVWFJbz5zU4ALrMZiTudleGF22sSGjljFBzfB2URolIi6IIgVBMR9DA4XW4en7OerzYf4ifn5nvblTntvmOLJjw7vD8tmqZAeQkoO6Q0je3i2g1Hd0fuI4IuCEI1EdUIw7SvtvH61zvYcrCUNxbtCDrusNm4on9bWD8bnuwAv28LJ0OsJRoKraFNf/82e0DJABF0QRCqiahGCMqrXPxx7kbv/paDpd5tjRFicbnNeVHbFvhOPHk4thtoN4x7E25f7Gu7e51RhMuDCLogCNVEVMPkrcW7WLOnBICiMDNCrXgF3Sq8lWWx3Uy7ILU5tDzT15aeYxTh8iCCLghCNZEYOsDObxg150cMr/gTL94ygk0Hjgd1GZyfzU+G5mNftwPWg92m4Ovn4Ltpvk7V8dDD0ay1MWAqeeiCIFQTEXTAvfD3ZKtS+tm2cd0rwQObfdtlcOuwzlzcMw+3KxvWQ/fWzeDT3/p3DJW1ouyGR25FW8rY3PBvSLbc86fzYOcisNlP4TcSBKExIoIOuNyRY0+zJp3n3ba5jdmiSYGzQyG0oCelQWWpf5vVQ+86wv9YVkfjRxAEoZpIoBZwuYNDIENsa3kr+Qluylrtf8BpxteLtwZfqOxIcJsjNbgtHqUBBEEQAhAPHd8AZzK+Wi1vJz8OwLkn1wD3WTqbJXH3h6g5Hs5D95DSHCqORY6hC4Ig1BDx0AGXGdNuQvTsFq+HHoqQMXTzT5yVDze8bzYmXCl4QRASAPHQAafLFHRVwRjb11zVoylYIyrLp0NuD3CehEV/DX+h1e8Gtx01SgaQ0swn7uKhC4JQCzRoQS8ureDJ/27gwdE9vGt+aq35YlMRWw6WsvlAKRPO7sDxvcc43w5X279ksG2jv5gDzLrDeE3Ljj010UOfawyhP+eXkN3ZaCv46an9YoIgCCFQWtfN439BQYFeunRpjc49Vl7F/zYfYvnOI5zVKZsUh4285qlBKwq9t6yQj1ftA+DBS3swb+1+qlxuVhaW+PX7R9ITnG9fQ5FuTq46VrNf6IdPwLwHoONQ2Pm10fbgfmNQVHLKBUGIE0qpZVrrglDHEtJDn/bR/1i4fA0A334duW9vU0s//K9vAaWfd81B2eB/mw8BkKFOANRczAEyzVRDu2U5OuuAqCAIQi2TeILucjJp3Xh+nRJ6fc+YKDRfUyL2ip3szsagJ0D+UCg9AAfXxenigiAIsZGAgl5Jqi5nUdMfcO7lcYxFJzc1JgClZhheds4ZcGQ7lB32HXOkQF4vKN5iJKoooOI4tOgKGe3gF4uMwdOzb4tc61wQBKEWSDxBNzNEjjfvBt0vqd17te4Xur3toNDteb2M15Rmxo8gCMJpJOHy0CuqjMk/TVKTo/QUBEFoXCScoJdXGgs1JzkS7+FCEAShNkk4Qa+sMqbe2+1SjVAQBMFKwgl6RaVR2MohHrogCIIfMQm6UmqUUmqjUmqLUuq+EMd/opQqUkqtMH9uib+pBhXioQuCIIQkqpurlLIDzwMjMTK4lyilZmmtAxOt39FaT6oFG/2oqDJi6A67eOiCIAhWYvHQBwNbtNbbtNaVwAzgito1KzxVThkUFQRBCEUsgt4W2G3ZLzTbArlaKbVKKTVTKdU+1IWUUrcqpZYqpZYWFRXVwFyoqDTSFiWGLgiC4E+8BkU/AvK11n2BT4E3Q3XSWk/TWhdorQtyc3NrdKPKKo+HLjF0QRAEK7EI+h7A6nG3M9u8aK2LtdaelR9eAcJMpTx1Kqs8HroIuiAIgpVYBH0J0E0p1UkplQyMB2ZZOyilWlt2xwDr42eiP5VOI20xyZFUW7cQBEFISKIGorXWTqXUJGAeYAde01qvVUo9CizVWs8C/k8pNQZwAoeBn9SWwVXioQuCIIQkppFFrfUcYE5A28OW7fuB++NrWmi8MfQk8dAFQRCsJNxM0cw0wzOXQVFBEAR/Ei73b0T3HFgoMXRBiDdVVVUUFhZSXn4Ki8cIcSM1NZV27dpVKxqRcILuqYeOSriHC0Go1xQWFtKsWTPy8/NRsg5unaK1pri4mMLCQjp16hTzeYmnim4RdEGoDcrLy2nRooWIeT1AKUWLFi2q/bSUeKro9dAlhi4I8UbEvP5Qk/9FAgq6kYeOvPEEQRD8SEBBNz10m3jogiAIVhJX0CWGLghCDXGaVVsbGomX5eL2hFzEQxeE2uJ3H61l3d5jcb1mzzbNeeTyXlH7XXnllezevZvy8nImT57Mrbfeyty5c3nggQdwuVzk5OTw+eefU1payh133MHSpUtRSvHII49w9dVX07RpU0pLSwGYOXMms2fP5o033uAnP/kJqampfP/99wwdOpTx48czefJkysvLSUtL4/XXX6d79+64XC5+85vfMHfuXGw2GxMnTqRXr14899xz/Oc//wHg008/5e9//zsffPBBXP9Gp0riCbp46ILQoHnttdfIzs7m5MmTnHXWWVxxxRVMnDiRL7/8kk6dOnH48GEAHnvsMTIyMli9ejUAR44ciXrtwsJCFi1ahN1u59ixY3z11Vc4HA4+++wzHnjgAd5//32mTZvGjh07WLFiBQ6Hg8OHD5OVlcXtt99OUVERubm5vP766/z0pz+t1b9DTUhAQfd46CLoglBbxOJJ1xbPPfec1/PdvXs306ZNY9iwYd587OzsbAA+++wzZsyY4T0vKysr6rXHjRvnXb6ypKSEm266ic2bN6OU8taJ+uyzz7jtttu8ay547nfjjTfyz3/+k5tvvplvvvmG6dOnx+k3jh8JKOjaeJVBUUFocCxcuJDPPvuMb775hiZNmjB8+HD69+/Phg0bYr6GNd0vMI87PT3du/3b3/6WCy+8kA8++IAdO3YwfPjwiNe9+eabufzyy0lNTWXcuHH1cpGdxHNz3ZK2KAgNlZKSErKysmjSpAkbNmzg22+/pby8nC+//JLt27cDeEMuI0eO5Pnnn/ee6wm55OXlsX79etxud8QYd0lJCW3bGouvvfHGG972kSNH8tJLL3kHTj33a9OmDW3atGHq1KncfPPN8ful40jiCbpMLBKEBsuoUaNwOp306NGD++67j3POOYfc3FymTZvG2LFj6devH9deey0ADz30EEeOHKF3797069ePBQsWAPDkk09y2WWXce6559K6deuw97r33nu5//77GTBggF/Wyy233EKHDh3o27cv/fr146233vIeu/7662nfvj09evSopb/AqaG0J4RxmikoKNBLly6t/onrZ8M718PPv4LWfeNvmCA0UtavX19vhaq+MGnSJAYMGMDPfvaz03K/UP8TpdQyrXVBqP71LwgUDc+gqMTQBUE4jQwaNIj09HSeeeaZujYlLAko6JK2KAjC6WfZsmV1bUJUEk8V3ZK2KAiCEIrEU0VPzF8GRQVBEPxIQEGXtEVBEIRQJKCgS7VFQRCEUCSuoEsMXRAEwY/EU0UZFBUEAWjatGldm1DvSOC0RQm5CEKt8d/7YP/q+F6zVR+45Mn4XrMe4HQ6601dl5jcXKXUKKXURqXUFqXUfRH6Xa2U0kqpkLOY4oJUWxSEBsl9993nV5tlypQpTJ06lREjRjBw4ED69OnDhx9+GNO1SktLw543ffp077T+G2+8EYADBw5w1VVX0a9fP/r168eiRYvYsWMHvXv39p739NNPM2XKFACGDx/OnXfeSUFBAc8++ywfffQRZ599NgMGDODiiy/mwIEDXjtuvvlm+vTpQ9++fXn//fd57bXXuPPOO73Xffnll7nrrrtq/HfzQ2sd8QewA1uBzkAysBLoGaJfM+BL4FugINp1Bw0apGvE4mlaP9Jc69Kimp0vCEJI1q1bV6f3X758uR42bJh3v0ePHnrXrl26pKREa611UVGR7tKli3a73VprrdPT08Neq6qqKuR5a9as0d26ddNFRYZ+FBcXa621vuaaa/Sf//xnrbXWTqdTHz16VG/fvl336tXLe82nnnpKP/LII1prrS+44AL9i1/8wnvs8OHDXrtefvllfffdd2uttb733nv15MmT/fodP35cd+7cWVdWVmqttR4yZIhetWpVyN8j1P8EWKrD6GoszwmDgS1a620ASqkZwBXAuoB+jwF/AO451S+ZiEgMXRAaJAMGDODgwYPs3buXoqIisrKyaNWqFXfddRdffvklNpuNPXv2cODAAVq1ahXxWlprHnjggaDz5s+fz7hx48jJyQF8tc7nz5/vrW9ut9vJyMiIumCGp0gYGAtnXHvttezbt4/Kykpv7fZwNdsvuugiZs+eTY8ePaiqqqJPnz7V/GuFJhZVbAvstuwXmm1elFIDgfZa648jXUgpdatSaqlSamlRUVG1jQUky0UQGjDjxo1j5syZvPPOO1x77bX861//oqioiGXLlrFixQry8vKCapyHoqbnWXE4HLjdbu9+pNrqd9xxB5MmTWL16tW89NJLUe91yy238MYbb/D666/HtRTvKauiUsoG/An4VbS+WutpWusCrXVBbm5uzW4ogi4IDZZrr72WGTNmMHPmTMaNG0dJSQktW7YkKSmJBQsWsHPnzpiuE+68iy66iPfee4/i4mLAV+t8xIgRvPDCCwC4XC5KSkrIy8vj4MGDFBcXU1FRwezZsyPez1Nb/c033/S2h6vZfvbZZ7N7927eeustJkyYEOufJyqxqOIeoL1lv53Z5qEZ0BtYqJTaAZwDzKq1gVEZFBWEBkuvXr04fvw4bdu2pXXr1lx//fUsXbqUPn36MH36dM4888yYrhPuvF69evHggw9ywQUX0K9fP+6++24Ann32WRYsWECfPn0YNGgQ69atIykpiYcffpjBgwczcuTIiPeeMmUK48aNY9CgQd5wDoSv2Q5wzTXXMHTo0JiWzouVqPXQlVIOYBMwAkPIlwDXaa3Xhum/EPi11jpisfMa10Pf8DGsehfGTgNHSvXPFwQhJFIP/fRy2WWXcddddzFixIiwfapbDz2qm6u1dgKTgHnAeuBdrfVapdSjSqkx1fkF4sKZo+GaN0XMBUFISI4ePcoZZ5xBWlpaRDGvCTFlw2ut5wBzAtoeDtN3+KmbJQiCEJ3Vq1d7c8k9pKSksHjx4jqyKDqZmZls2rSpVq5dP6Y3CYJQL9BaoxKokmmfPn1YsWJFXZtRK0QLh4dCRhYFQQAgNTWV4uLiGgmJEF+01hQXF5Oamlqt88RDFwQBgHbt2lFYWEiN54gIcSU1NZV27dpV6xwRdEEQAEhKSvLOcBQSEwm5CIIgNBBE0AVBEBoIIuiCIAgNhKgzRWvtxkoVAbEVZggmBzgUR3NqE7G1dhBba49Esrcx2tpRax2yGFadCfqpoJRaGm7qa31DbK0dxNbaI5HsFVv9kZCLIAhCA0EEXRAEoYGQqII+ra4NqAZia+0gttYeiWSv2GohIWPogiAIQjCJ6qELgiAIAYigC4IgNBASTtCVUqOUUhuVUluUUvfVA3teU0odVEqtsbRlK6U+VUptNl+zzHallHrOtH2Vubj26bS188mN6QAABARJREFUvVJqgVJqnVJqrVJqcn21VymVqpT6Tim10rT1d2Z7J6XUYtOmd5RSyWZ7irm/xTyef7pstdhsV0p9r5SaXZ9tVUrtUEqtVkqtUEotNdvq3XvAvH+mUmqmUmqDUmq9UmpIfbRVKdXd/Ht6fo4ppe487bZqrRPmB7ADW4HOQDKwEuhZxzYNAwYCayxtfwTuM7fvA/5gbl8K/BdQGGuvLj7NtrYGBprbzTCWFuxZH+0179nU3E4CFps2vAuMN9tfBH5hbt8OvGhujwfeqYP3wt3AW8Bsc79e2grsAHIC2urde8C8/5vALeZ2MpBZX2212GwH9gMdT7etp/2XPcU/1BBgnmX/fuD+emBXfoCgbwRam9utgY3m9kvAhFD96sjuD4GR9d1eoAmwHDgbY6adI/D9gLFE4hBz22H2U6fRxnbA58BFwGzzg1pfbQ0l6PXuPQBkANsD/zb10dYA+34AfF0XtiZayKUtsNuyX2i21TfytNb7zO39QJ65XW/sNx/zB2B4vvXSXjOEsQI4CHyK8XR2VBvr3Aba47XVPF4CtDhdtgJ/Ae4F3OZ+C+qvrRr4RCm1TCl1q9lWH98DnYAi4HUzlPWKUiq9ntpqZTzwtrl9Wm1NNEFPOLTx9VuvckOVUk2B94E7tdbHrMfqk71aa5fWuj+G9zsYOLOOTQqJUuoy4KDWelld2xIj52mtBwKXAL9USg2zHqxH7wEHRjjzBa31AOAERtjCSz2yFQBznGQM8F7gsdNha6IJ+h6gvWW/ndlW3ziglGoNYL4eNNvr3H6lVBKGmP9La/1vs7ne2gugtT4KLMAIW2QqpTwLs1jt8dpqHs8Aik+TiUOBMUqpHcAMjLDLs/XUVrTWe8zXg8AHGF+W9fE9UAgUaq09Kz7PxBD4+mirh0uA5VrrA+b+abU10QR9CdDNzB5Ixni0mVXHNoViFnCTuX0TRqza0/5jc4T7HKDE8jhW6yilFPAqsF5r/af6bK9SKlcplWlup2HE+tdjCPuPwtjq+R1+BMw3PaJaR2t9v9a6ndY6H+M9OV9rfX19tFUpla6UaubZxoj3rqEevge01vuB3Uqp7mbTCGBdfbTVwgR84RaPTafP1tM9YBCHAYdLMbIztgIP1gN73gb2AVUYHsXPMOKhnwObgc+AbLOvAp43bV8NFJxmW8/DeORbBawwfy6tj/YCfYHvTVvXAA+b7Z2B74AtGI+1KWZ7qrm/xTzeuY7eD8PxZbnUO1tNm1aaP2s9n6H6+B4w798fWGq+D/4DZNVjW9MxnrQyLG2n1VaZ+i8IgtBASLSQiyAIghAGEXRBEIQGggi6IAhCA0EEXRAEoYEggi4IgtBAEEEXBEFoIIigC4IgNBD+H9WldX0wv7CxAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAd7RBDZM1fe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3703bb4e-c4fc-4928-95da-fe0de2984a6c"
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"The test_loss is: {}, and the test_accuracy is: {}\".format(test_loss, test_accuracy))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100/100 [==============================] - 0s 98us/step\n",
            "The test_loss is: 0.06927556594833732, and the test_accuracy is: 0.9700000286102295\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBc5-pyQNTrF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_predicted = model.predict(X_test)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ozkRX_ZNry9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "db55a118-8a05-4bef-c8fc-9a23b47ceb01"
      },
      "source": [
        "y_predicted"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.79015728e-06, 8.40862704e-05, 1.37677560e-07, 9.99912024e-01],\n",
              "       [8.10474812e-05, 3.08462040e-05, 4.75996176e-09, 9.99888062e-01],\n",
              "       [3.99765995e-05, 9.62089658e-01, 7.67780861e-09, 3.78702730e-02],\n",
              "       [1.89204923e-06, 4.01202078e-06, 2.16415458e-07, 9.99993920e-01],\n",
              "       [1.35709152e-01, 6.90143497e-04, 5.85036901e-07, 8.63600194e-01],\n",
              "       [5.36636981e-05, 5.63058376e-01, 9.00294950e-09, 4.36888009e-01],\n",
              "       [1.12405189e-07, 5.43353917e-06, 4.61152921e-10, 9.99994397e-01],\n",
              "       [7.93870058e-05, 5.97972074e-04, 5.31805222e-09, 9.99322653e-01],\n",
              "       [1.22004358e-05, 9.91738617e-01, 4.58422328e-11, 8.24928191e-03],\n",
              "       [8.72495413e-01, 3.32559482e-03, 7.87401646e-08, 1.24178842e-01],\n",
              "       [5.91942808e-07, 1.32564455e-04, 7.64794361e-09, 9.99866843e-01],\n",
              "       [2.99898402e-05, 9.28977787e-01, 3.52384347e-07, 7.09918439e-02],\n",
              "       [5.88483715e-07, 7.48460443e-05, 2.04894679e-08, 9.99924541e-01],\n",
              "       [2.99428052e-06, 3.19423743e-05, 7.27898225e-07, 9.99964356e-01],\n",
              "       [8.98718540e-08, 1.02762002e-04, 9.97193515e-01, 2.70363432e-03],\n",
              "       [2.10111721e-05, 3.13640194e-05, 2.07921342e-08, 9.99947548e-01],\n",
              "       [2.06381455e-03, 1.29717530e-03, 4.29575884e-05, 9.96596038e-01],\n",
              "       [2.10766564e-04, 9.47488666e-01, 9.80129755e-10, 5.23005091e-02],\n",
              "       [5.39950037e-04, 1.15162425e-03, 2.63451540e-07, 9.98308182e-01],\n",
              "       [2.73518145e-01, 4.73028456e-04, 2.49414342e-07, 7.26008594e-01],\n",
              "       [9.75284129e-05, 9.43476677e-01, 2.87910029e-06, 5.64228520e-02],\n",
              "       [1.84989972e-07, 2.00810950e-06, 1.06486049e-10, 9.99997854e-01],\n",
              "       [4.71890780e-05, 8.25538649e-04, 3.05598462e-08, 9.99127209e-01],\n",
              "       [7.70877450e-05, 9.55869317e-01, 1.34129952e-09, 4.40535657e-02],\n",
              "       [9.81796324e-01, 5.39021916e-04, 9.97441685e-09, 1.76647846e-02],\n",
              "       [7.86672388e-07, 6.59789248e-06, 4.55329641e-09, 9.99992609e-01],\n",
              "       [1.52913140e-04, 9.04046237e-01, 1.10508654e-05, 9.57897305e-02],\n",
              "       [6.12009899e-07, 2.47997505e-05, 4.66960195e-08, 9.99974489e-01],\n",
              "       [2.37020813e-05, 7.29823543e-04, 1.62792530e-05, 9.99230146e-01],\n",
              "       [1.65043502e-07, 2.16929257e-05, 9.94395852e-01, 5.58237638e-03],\n",
              "       [8.53756683e-06, 7.33226130e-04, 6.32857882e-06, 9.99251902e-01],\n",
              "       [3.15281941e-05, 7.00913806e-05, 4.59370959e-08, 9.99898314e-01],\n",
              "       [5.15068587e-06, 9.55867350e-01, 3.53124932e-07, 4.41271923e-02],\n",
              "       [3.00686550e-03, 5.13528357e-04, 2.11296562e-08, 9.96479571e-01],\n",
              "       [9.90778208e-01, 3.40367144e-04, 3.05073300e-09, 8.88140500e-03],\n",
              "       [3.32138501e-04, 5.97658694e-01, 9.34907348e-07, 4.02008206e-01],\n",
              "       [5.60162164e-07, 4.12350300e-06, 4.59283171e-08, 9.99995232e-01],\n",
              "       [1.15856482e-03, 3.30775918e-04, 5.10308129e-10, 9.98510659e-01],\n",
              "       [5.76540246e-04, 8.65991473e-01, 3.10254904e-07, 1.33431673e-01],\n",
              "       [6.50705338e-01, 4.32302104e-03, 1.22318999e-08, 3.44971746e-01],\n",
              "       [1.79884921e-07, 4.73869950e-05, 1.53158519e-09, 9.99952435e-01],\n",
              "       [1.76940357e-05, 9.91609395e-01, 3.09025012e-07, 8.37254710e-03],\n",
              "       [5.30636771e-06, 6.62935840e-04, 4.34252579e-05, 9.99288380e-01],\n",
              "       [6.16445395e-05, 1.44406396e-04, 7.72647979e-07, 9.99793231e-01],\n",
              "       [2.29398069e-07, 4.01946500e-06, 9.99630451e-01, 3.65188869e-04],\n",
              "       [2.11032457e-04, 7.77519832e-04, 4.31631975e-07, 9.99011040e-01],\n",
              "       [1.95166402e-04, 3.72909184e-04, 1.63769096e-06, 9.99430239e-01],\n",
              "       [1.33464118e-05, 9.97385800e-01, 1.48364121e-09, 2.60088476e-03],\n",
              "       [3.37922946e-04, 1.30793743e-03, 4.27922441e-06, 9.98349905e-01],\n",
              "       [9.91113484e-01, 2.43689865e-04, 5.73631203e-12, 8.64276942e-03],\n",
              "       [3.99450044e-04, 9.97212470e-01, 4.44111130e-08, 2.38809315e-03],\n",
              "       [5.17151011e-06, 2.13336098e-05, 9.32378086e-09, 9.99973536e-01],\n",
              "       [8.09379620e-04, 2.98166042e-03, 1.48827235e-06, 9.96207476e-01],\n",
              "       [4.32078465e-04, 9.51268733e-01, 2.16910205e-08, 4.82992306e-02],\n",
              "       [9.62449849e-01, 1.98872318e-03, 1.33891289e-08, 3.55615020e-02],\n",
              "       [2.29961813e-07, 1.66511047e-04, 5.77344794e-09, 9.99833226e-01],\n",
              "       [2.22601484e-05, 9.83722866e-01, 1.10069695e-05, 1.62438229e-02],\n",
              "       [9.96728318e-07, 2.97841238e-04, 7.31718455e-06, 9.99693871e-01],\n",
              "       [4.92166146e-05, 1.48335984e-03, 9.07023496e-04, 9.97560382e-01],\n",
              "       [2.03467412e-08, 1.29312830e-05, 9.99934316e-01, 5.27418997e-05],\n",
              "       [2.73898157e-04, 3.09746922e-03, 2.41512185e-04, 9.96387124e-01],\n",
              "       [9.94259608e-05, 1.89666508e-03, 3.10062774e-06, 9.98000801e-01],\n",
              "       [5.98867948e-04, 9.41900492e-01, 1.25612823e-05, 5.74880764e-02],\n",
              "       [5.07304285e-05, 3.29974500e-05, 1.73654797e-07, 9.99916077e-01],\n",
              "       [4.86934155e-01, 5.30083256e-04, 9.13251341e-08, 5.12535691e-01],\n",
              "       [3.53466348e-05, 9.84585345e-01, 1.10073883e-09, 1.53793050e-02],\n",
              "       [1.24548285e-06, 3.88493972e-05, 1.31695058e-10, 9.99959946e-01],\n",
              "       [9.34288604e-04, 2.97768693e-03, 4.12988957e-12, 9.96088028e-01],\n",
              "       [1.47484010e-04, 9.88036633e-01, 7.59515974e-12, 1.18158478e-02],\n",
              "       [9.40503478e-01, 4.65525460e-04, 2.89538359e-13, 5.90310171e-02],\n",
              "       [5.27169959e-06, 3.23239336e-04, 3.52801087e-11, 9.99671459e-01],\n",
              "       [3.67425600e-05, 9.65894461e-01, 2.21536311e-06, 3.40666547e-02],\n",
              "       [3.01617138e-06, 6.48629793e-05, 6.10610158e-08, 9.99932051e-01],\n",
              "       [6.11359428e-05, 8.71617522e-05, 7.14554881e-06, 9.99844551e-01],\n",
              "       [2.90526327e-06, 7.25440841e-05, 9.98919725e-01, 1.00484828e-03],\n",
              "       [9.16348491e-03, 3.26943863e-03, 1.04648859e-11, 9.87567067e-01],\n",
              "       [1.17869591e-02, 1.26678552e-02, 2.39731273e-11, 9.75545228e-01],\n",
              "       [5.09857258e-04, 9.98756409e-01, 1.00107429e-10, 7.33826950e-04],\n",
              "       [5.05988719e-03, 2.96634622e-02, 1.73327894e-08, 9.65276599e-01],\n",
              "       [9.74977076e-01, 4.50070183e-05, 1.28238176e-09, 2.49779411e-02],\n",
              "       [1.05992274e-03, 9.28586721e-01, 1.39848012e-07, 7.03533292e-02],\n",
              "       [1.72210675e-05, 4.05348474e-05, 3.29216376e-11, 9.99942183e-01],\n",
              "       [4.04663471e-04, 2.39442475e-03, 3.56776186e-09, 9.97200966e-01],\n",
              "       [8.02336261e-04, 9.86452460e-01, 3.63790720e-10, 1.27452668e-02],\n",
              "       [9.99163628e-01, 6.84499508e-04, 6.13186169e-11, 1.51814558e-04],\n",
              "       [9.17297621e-06, 6.60769947e-05, 4.23772600e-10, 9.99924779e-01],\n",
              "       [1.41395765e-04, 9.93325710e-01, 4.58356020e-08, 6.53289119e-03],\n",
              "       [5.22204300e-06, 3.27137750e-05, 6.14591272e-07, 9.99961495e-01],\n",
              "       [5.39239118e-05, 5.74896367e-05, 1.57782470e-05, 9.99872804e-01],\n",
              "       [1.80001587e-06, 4.59213288e-06, 9.99740064e-01, 2.53499631e-04],\n",
              "       [6.48105983e-04, 2.51284312e-03, 9.22565414e-06, 9.96829808e-01],\n",
              "       [1.07999574e-02, 7.61227543e-03, 7.33695493e-10, 9.81587768e-01],\n",
              "       [4.41490393e-03, 9.91037130e-01, 1.16464116e-09, 4.54797735e-03],\n",
              "       [4.89407917e-03, 1.05658229e-02, 2.38188392e-07, 9.84539807e-01],\n",
              "       [9.73437428e-01, 7.18822982e-03, 5.10756536e-07, 1.93738248e-02],\n",
              "       [6.26660176e-06, 9.87358332e-01, 3.77567275e-08, 1.26354676e-02],\n",
              "       [1.72125951e-07, 3.08308481e-05, 2.06742978e-08, 9.99969006e-01],\n",
              "       [1.01677340e-03, 2.15215236e-03, 1.06081838e-10, 9.96831119e-01],\n",
              "       [1.38252362e-05, 9.99093890e-01, 2.57924593e-09, 8.92299693e-04],\n",
              "       [9.80212450e-01, 3.36768921e-04, 3.99330846e-11, 1.94508098e-02]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    }
  ]
}